[
  {
    "objectID": "arma.html",
    "href": "arma.html",
    "title": "ARMA and ARIMA Models",
    "section": "",
    "text": "ARMA and ARIMA Models are used in time-series in order to forecast the time series object at had. Thus, we will take a look at both the globalization index as well as the stock fluctuation of HYBE Co. in order to forecast values and make future predictions. These metrics will help us determine the impact globalization in conjunction with record labels like HYBE have within the United States and the Western music world."
  },
  {
    "objectID": "arma.html#globalization-index",
    "href": "arma.html#globalization-index",
    "title": "ARMA and ARIMA Models",
    "section": "Globalization Index:",
    "text": "Globalization Index:\nFrom our Exploratory Data Analysis, we noticed the following information:\n\nPrior to differncing, the ACF plot show several lags above the significance bands, indicating a non-stationary relationship.\nThe Augmented Dickey-Fuller Test confirmed that the data itself was NOT stationary.\n\nThus, using this information, we will move on to differencing to fit the data to become stationary:\n\n\nDifferencing Code\ndff_global &lt;- diff(global_ts)\np1 &lt;- ggAcf(dff_global)+ggtitle(\"ACF Plot for First Differenced Globalization Index\")\np2 &lt;- ggPacf(dff_global)+ggtitle(\"PACF Plot for First Differenced Globalization Index\")\n\ngrid.arrange(p1, p2, nrow=2)\n\n\n\n\n\nFrom the ACF and PACF plots of the first differenced time series object, we can now see that lag values are all contained inside the significance bands, meaning that this distribution is in fact, stationary.\nLet’s see the Augumented Dickey-Fuller score for the first differenced data:\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  dff_global\nDickey-Fuller = -3.244, Lag order = 3, p-value = 0.09043\nalternative hypothesis: stationary\n\n\nUnfortunetly, since the ADF p-value is 0.09043 &gt; 0.05, we fail to reject the null hypothesis. From teh ADF test, the distribution is still stationary. However, because this score is not allows accurate, we will assume the results of the ACF plots are correct to avoid over-differencing.\nThus from the plot, we can also state the following:\n\nSince the ACF plot doesn’t have any significant peaks, q = 0.\nSince the PACF plot doesn’t have any significant peaks, p = 0.\nSince we differenced once, d = 1.\n\nWhile q and p are zero based on the graph, it’s better to run through a multitude of options in order to find the best model for this data.\nNow, let’s move to creating the ARIMA model:\n\n\nARIMA Model\nset.seed(123)\n\nd=1\ni=1\ntemp= data.frame()\nls=matrix(rep(NA,6*25),nrow=25) # roughly nrow = 5x2 (see below)\n\n\nfor (p in 0:4)# p=0,1,2,3,4 : 5\n{\n  for(q in 0:4)# q=0,1,2,3,4 :5\n  {\n    model&lt;- Arima(dff_global,order=c(p,d,q),include.drift=TRUE) \n    ls[i,]= c(p,d,q,model$aic,model$bic,model$aicc)\n    i=i+1\n  }\n}\n\ntemp= as.data.frame(ls)\nnames(temp)= c(\"p\",\"d\",\"q\",\"AIC\",\"BIC\",\"AICc\")\n\n#temp\nknitr::kable(temp)\n\n\n\n\n\np\nd\nq\nAIC\nBIC\nAICc\n\n\n\n\n0\n1\n0\n131.6564\n135.4400\n131.9173\n\n\n0\n1\n1\n104.6809\n110.3564\n105.2143\n\n\n0\n1\n2\n106.6801\n114.2474\n107.5892\n\n\n0\n1\n3\n108.6416\n118.1007\n110.0369\n\n\n0\n1\n4\n110.6011\n121.9520\n112.6011\n\n\n1\n1\n0\n121.0974\n126.7728\n121.6307\n\n\n1\n1\n1\n106.6801\n114.2474\n107.5892\n\n\n1\n1\n2\n108.6249\n118.0840\n110.0203\n\n\n1\n1\n3\n110.6009\n121.9518\n112.6009\n\n\n1\n1\n4\n112.3465\n125.5893\n115.0782\n\n\n2\n1\n0\n117.9095\n125.4768\n118.8186\n\n\n2\n1\n1\n108.6378\n118.0969\n110.0332\n\n\n2\n1\n2\n110.6237\n121.9747\n112.6237\n\n\n2\n1\n3\n112.6505\n125.8933\n115.3822\n\n\n2\n1\n4\n112.5356\n127.6701\n116.1356\n\n\n3\n1\n0\n115.7033\n125.1625\n117.0987\n\n\n3\n1\n1\n110.6820\n122.0329\n112.6820\n\n\n3\n1\n2\n112.3893\n125.6320\n115.1210\n\n\n3\n1\n3\n112.5393\n127.6739\n116.1393\n\n\n3\n1\n4\n114.8561\n131.8825\n119.4715\n\n\n4\n1\n0\n116.1590\n127.5099\n118.1590\n\n\n4\n1\n1\n112.5199\n125.7626\n115.2516\n\n\n4\n1\n2\n114.3512\n129.4858\n117.9512\n\n\n4\n1\n3\n116.3600\n133.3864\n120.9754\n\n\n4\n1\n4\n116.5290\n135.4472\n122.3184\n\n\n\n\n\nThus, we can easily view that the best model has values p=0, d=1, and q=1. Let’s find the equation\n\n\nCode\nsarima(dff_global, 0, 1, 1)\n\n\ninitial  value -0.116322 \niter   2 value -0.299568\niter   3 value -0.343985\niter   4 value -0.373735\niter   5 value -0.395774\niter   6 value -0.410452\niter   7 value -0.413059\niter   8 value -0.413103\niter   9 value -0.413515\niter  10 value -0.413515\niter  11 value -0.413517\niter  12 value -0.413518\niter  12 value -0.413518\niter  12 value -0.413518\nfinal  value -0.413518 \nconverged\ninitial  value -0.405399 \niter   2 value -0.405743\niter   3 value -0.411760\niter   4 value -0.411935\niter   5 value -0.411961\niter   6 value -0.411978\niter   7 value -0.411986\niter   8 value -0.411988\niter   9 value -0.411990\niter   9 value -0.411990\niter   9 value -0.411990\nfinal  value -0.411990 \nconverged\n\n\n\n\n\n$fit\n\nCall:\narima(x = xdata, order = c(p, d, q), seasonal = list(order = c(P, D, Q), period = S), \n    xreg = constant, transform.pars = trans, fixed = fixed, optim.control = list(trace = trc, \n        REPORT = 1, reltol = tol))\n\nCoefficients:\n          ma1  constant\n      -1.0000   -0.0136\ns.e.   0.1032    0.0062\n\nsigma^2 estimated as 0.405:  log likelihood = -49.34,  aic = 104.68\n\n$degrees_of_freedom\n[1] 47\n\n$ttable\n         Estimate     SE t.value p.value\nma1       -1.0000 0.1032 -9.6922  0.0000\nconstant  -0.0136 0.0062 -2.1783  0.0344\n\n$AIC\n[1] 2.136345\n\n$AICc\n[1] 2.141669\n\n$BIC\n[1] 2.252171\n\n\nFrom the results of the sarima() function, we call say that the equation is as follows:\n\\[\\begin{align}\nx_{t} = w_{t} -1w_{t-1} - 0.0136\n\\end{align}\\]\nFrom the model diagonotics presented, we can also say that the ACF plot of residuals shows no significance, meaning the residuals are not correlated. However, the p-values of the Ljung-Box statistic is much higher than the significance band. While this is not great, we can still move forward since the residuals are not significant and that this was the best model of the ones simulated.\nNow let’s varify with auto arima:\n\n\nSeries: dff_global \nARIMA(0,1,1) \n\nCoefficients:\n          ma1\n      -0.8793\ns.e.   0.0718\n\nsigma^2 = 0.4492:  log likelihood = -50.16\nAIC=104.32   AICc=104.58   BIC=108.1\n\n\nauto.arima() also chose the same model I concluded with, thus we will continue with this model.\nNow let’s look at the forecast:\nFirst, let’s forecast based on the best model\n\n\nForecasting\nfit &lt;- Arima(dff_global, order=c(0, 1, 1))\nautoplot(forecast(fit))\n\n\n\n\n\nFrom the looks of the forecast, we can see a very large confidence band with the values mostly following the overal trend of the differenced data. Let’s compare to the naive approaches:\n\n\nForecast comparison\nsummary(fit)\n\n\nSeries: dff_global \nARIMA(0,1,1) \n\nCoefficients:\n          ma1\n      -0.8793\ns.e.   0.0718\n\nsigma^2 = 0.4492:  log likelihood = -50.16\nAIC=104.32   AICc=104.58   BIC=108.1\n\nTraining set error measures:\n                   ME      RMSE      MAE      MPE     MAPE      MASE\nTraining set -0.05512 0.6566845 0.503263 140.2474 227.9084 0.6989056\n                    ACF1\nTraining set -0.05065878\n\n\nForecast comparison\nautoplot(dff_global) +\n  autolayer(meanf(dff_global, h=11),\n            series=\"Mean\", PI=FALSE) +\n  autolayer(naive(dff_global, h=11),\n            series=\"Naïve\", PI=FALSE) +\n  autolayer(snaive(dff_global, h=11),\n            series=\"Seasonal naïve\", PI=FALSE) +\n  autolayer(forecast(fit, h=11),\n            series=\"Fit\", PI=FALSE) +\n  ggtitle(\"Forecasts for yearly globalization metric\") +\n  xlab(\"Year\") + ylab(\"KOF Index\") +\n  guides(colour=guide_legend(title=\"Forecast\"))\n\n\n\n\n\nAfter mapping the model with other benchmarks, it’s clear that none of the functions, fitted or benchmarks, accurately forecasts the differenced data. The fitted data seems to the only line approximately in the same range as the overall trend, however, none of them are accurate functions. As a result of this information, it may be worth taking a look at this data un-differenced in order to get a better insight of the globalization index."
  },
  {
    "objectID": "arimax.html",
    "href": "arimax.html",
    "title": "ARIMAX/SARIMAX/VAR",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "conclusions.html",
    "href": "conclusions.html",
    "title": "Conclusions",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "financial-ts.html",
    "href": "financial-ts.html",
    "title": "Financial Time Series Models (ARCH/GARCH)",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "saf.html",
    "href": "saf.html",
    "title": "Spectral Analysis and Filtering",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "deep-learning.html",
    "href": "deep-learning.html",
    "title": "Deep Learning for TS",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "data-sources.html",
    "href": "data-sources.html",
    "title": "Data Sources",
    "section": "",
    "text": "Streaming\n\n\n\n\n\nClick the image to view the API\nThe spotify API allows for access to all kinds of streaming data including artist music records and an analysis on their musical compponents. Using spotify data, I plan to analyze overall trends of popular music throughout the years as well as specific international artists with popular debuts in the U.S.\nFor example, here is a plot the artists Taylor Swift, BTS, and Twice and their music’s danceability over a period of 10 years.\n\n\nCode\naccess_token &lt;- get_spotify_access_token()\nartists &lt;- c(\"BTS\", \"Taylor Swift\", \"Twice\")\n\nBTS &lt;- get_artist_audio_features(\"BTS\")\nBTS_A &lt;- data.frame(BTS$artist_name,\nBTS$instrumentalness,\nBTS$valence,\nBTS$danceability,\nBTS$energy,\nBTS$loudness,\nBTS$speechiness,\nBTS$acousticness,\nBTS$liveness,\nBTS$tempo,\nBTS$track_name,\nBTS$album_name,\nBTS$album_release_year,\nBTS$album_release_date)\n\ncolnames(BTS_A) &lt;- c(\"artist_name\",\"instrumentalness\",\"Valence\",\"danceability\",\"energy\",\n\"loudness\",\"speechiness\",\"acousticness\",\"liveness\",\n\"tempo\",\"track_name\",\"album_name\",\"album_release_year\",\"date\")\n\nTaylor_Swift &lt;- get_artist_audio_features(\"Taylor Swift\")\nTaylor_Swift_A &lt;- data.frame(Taylor_Swift$artist_name,\nTaylor_Swift$instrumentalness,\nTaylor_Swift$valence,\nTaylor_Swift$danceability,\nTaylor_Swift$energy,\nTaylor_Swift$loudness,\nTaylor_Swift$speechiness,\nTaylor_Swift$acousticness,\nTaylor_Swift$liveness,\nTaylor_Swift$tempo,\nTaylor_Swift$track_name,\nTaylor_Swift$album_name,\nTaylor_Swift$album_release_year,\nTaylor_Swift$album_release_date)\n\ncolnames(Taylor_Swift_A) &lt;- c(\"artist_name\",\"instrumentalness\",\"Valence\",\"danceability\",\"energy\",\n\"loudness\",\"speechiness\",\"acousticness\",\"liveness\",\n\"tempo\",\"track_name\",\"album_name\",\"album_release_year\",\"date\")\n\n\nTwice &lt;- get_artist_audio_features(\"Twice\")\nTwice_A &lt;- data.frame(Twice$artist_name,\nTwice$instrumentalness,\nTwice$valence,\nTwice$danceability,\nTwice$energy,\nTwice$loudness, \nTwice$speechiness,\nTwice$acousticness,\nTwice$liveness,\nTwice$tempo,\nTwice$track_name,\nTwice$album_name,\nTwice$album_release_year,\nTwice$album_release_date)\n\ncolnames(Twice_A) &lt;- c(\"artist_name\",\"instrumentalness\",\"Valence\",\"danceability\",\"energy\",\n\"loudness\",\"speechiness\",\"acousticness\",\"liveness\",\n\"tempo\",\"track_name\",\"album_name\",\"album_release_year\",\"date\")\n\nartists &lt;- rbind(BTS_A, Taylor_Swift_A, Twice_A)\nartists$date &lt;- as.Date(artists$date, format = \"%Y-%m-%d\")\n\nfig &lt;- plot_ly(artists, x = ~date, y = ~danceability, color = ~artist_name, \n               type = 'scatter', mode = 'markers', size = ~speechiness) \n\nfig &lt;- fig %&gt;% layout(xaxis = list(title = \"Album Released Date\"),\n                      yaxis = list(title =\"Danceability\"), \n                      title = \"Danceability - Taylor Swift/BTS/Twice\")\n\nfig\n\n\n\n\n\n\nWe can see that the prior to the introduction of international stars BTS and Twice, American artist Taylor Swift had a lower degree of danceability and speechiness. Both increased as BTS and Twice entered the market, noting a slight shift in the music trends.\n\n\nMusic Charts\n\n\n\n\n\nClick the image to download the dataset\nOne of the longest music charting services is the Billboard Chart. Every week, starting from 1958, the Billboard charts have documented the 100 top songs in the U.S. Thus, I will be using this data to anaylze the most popular songs throughout 1958-2021. Augmenting this data with genres of the songs and orgins of the artist can help further describe the globalization trends in music charting.\n\n\nMusic Stock:\nUsing the Quantmod package, we can analyze the stock prices of several music record companies over a course of multiple years. This will allow us to identify specific trends within the music industry as well as interpret shareholder’s opinions of globalization news throughout history.\n\n\nCode\n# basic example of ohlc charts\ndf &lt;- data.frame(Date=index(UMGNF),coredata(UMGNF))\ndf &lt;- tail(df, 365)\n\nfig &lt;- df %&gt;% plot_ly(x = ~Date, type=\"candlestick\",\n          open = ~UMGNF.Open, close = ~UMGNF.Close,\n          high = ~UMGNF.High, low = ~UMGNF.Low) \nfig &lt;- fig %&gt;% layout(title = \"Universal Music Group Candlestick Chart\")\n\nfig\n\n\n\n\n\n\n\n\nQuantifying Globalization\n\n\n\n\n\nClick here to download the data\nThe KOF Globalization index is a way to quantify globalization of a country. This metric was started in the 1970’s as countries increasingly began to embrace globalization. This metric can be used in tandum with music trends in order to decipher if musical globalization is happening concurrently with general globalization.\n\n\nLive Music\n\n\n\n\n\nUsing revenue data from the world tours of all 8 artists over their careers (up until the last decade), we will be able to analyze the economic impact of concerts in the United States, both from Western and KPOP artists.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "eda.html",
    "href": "eda.html",
    "title": "Exploratory Data Analysis",
    "section": "",
    "text": "Now, I will be conducting a Time Series EDA analysis on the globalization indexes and the record label stock prices. Due to the structure of the other data, I cannot conduct further time series EDA on those sets.\nImporting Libraries\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(forecast)\nlibrary(astsa) \nlibrary(xts)\nlibrary(tseries)\nlibrary(fpp2)\nlibrary(fma)\nlibrary(lubridate)\nlibrary(tidyverse)\nlibrary(TSstudio)\nlibrary(quantmod)\nlibrary(tidyquant)\nlibrary(plotly)\nlibrary(ggplot2)\nlibrary(imputeTS)\nlibrary(gridExtra)\nlibrary(reticulate)\nuse_python(\"/usr/local/bin/python3\", require = T)\nknitr::knit_engines$set(python = reticulate::eng_python)"
  },
  {
    "objectID": "eda.html#globalization",
    "href": "eda.html#globalization",
    "title": "Exploratory Data Analysis",
    "section": "Globalization:",
    "text": "Globalization:\nLet’s begin by anaylzing globalization of the United States from 1970 to 2022. I will be using the general globalization index for this time series anaylsis. First I will begin by filtering the data and creating a time series object in R. This will allow us to plot the time series data for initial analysis.\n\nTime Series plot:\n\n\nCode\n# Import dataset\nglobal &lt;- read_csv('globalization.csv')\n\n# Filter information\nglobal &lt;- global %&gt;%\n  filter(country == 'United States') %&gt;%\n  select(year, KOFGI) %&gt;%\n  mutate(year = as.Date(year))\n\n# Create time series\nglobal_ts &lt;-ts(global$KOFGI, star=decimal_date(as.Date(\"1970-01-01\", format = \"%Y-%m-%d\")), frequency = 1)\n\n# Create time series plot\nglobal_plot &lt;- plot(as.ts(global_ts), main = \"Time Series of KOF Globalization Index within the United States\",\n                  xlab = 'Time', ylab = 'KOF Index')\n\n\n\n\n\nCode\n# Show plot\nggplotly(global_plot)\n\n\n\n\n\nFrom the plot of the globalization index in the United States, we can see a strong positive upward trend. In terms of seasonality and cyclic patterns, we are unable to see such patterns in the plot. Additionally, we can see very slight peaks in the data in 1986 and 2009, however, they are not enough to conclude any patterns in the data. Thus,we can say this plot is neither additive nor multiplicative.\nNext, we’ll take a look at a moving average smoothing plot to obtain some information on potential crossings.\n\n\nMoving Average Smoothing:\n\n\nSMA Code\nimport pandas as pd\nimport datetime\nimport plotly \nfrom datetime import datetime \nfrom pandas_datareader import data as pdr\nimport plotly.offline as pyo\nimport plotly.graph_objects as go \nfrom plotly.subplots import make_subplots\nimport plotly.express as px\n\nglobal_data = pd.read_csv('globalization.csv')\nglobal_data = global_data[global_data['country'] == 'United States']\nglobal_data['year'] = pd.to_datetime(global_data['year'], format='%Y')\n\nglobal_data['5yma'] = global_data['KOFGI'].rolling(window = 5).mean()\nglobal_data['10yma'] = global_data['KOFGI'].rolling(window = 10).mean()\nglobal_data['20yma'] = global_data['KOFGI'].rolling(window = 20).mean()\n\nfig = px.line(global_data, x='year', y=['KOFGI', '5yma', '10yma', '20yma'],\n              labels={'value': 'Yearly Data', 'variable': 'Moving Average'},\n              title='Yearly Data and Moving Averages for the Globalization Index')\n\n# Show the plot\nfig.show()\n\n\n\n                        \n                                            \n\n\nThis plot shows us the smoothing moving average for the yearly KOF globalization index data. The three types of smoothing I chose was 5-year, 10-year, and 20-year moving averages. As we can see in the graph, all smoothing lines show a positive upward trend across the time interval (the past 50 years). There is also no crossing between the smoothing lines, possibly indicating that the data had a constant upward trend with no seasonality or cyclical trends throughout.\nNext, let’s take a look at a few lag plots of data on itself as well ACF and PACF in order to identify possible signs of stationarity.\n\n\nLag-plot:\n\n\nCode\ngglagplot(global_ts, do.lines=FALSE)+ggtitle(\"Lag Plot for the KOF Globalization Index\")\n\n\n\n\n\nWe can see in lags 1,2, and 3 a very strong positive linear relationship, meaning a positive autocorrelation in the lags. From lag 4 and onward, the trend is still strongly positive, but less linear, suggesting a weaker autocorrelation. We also don’t see any groupings in the lags, suggesting that there is no seasonality in the data.\n\n\nACF & PACF:\n\n\nCode\nggAcf(global_ts)+ggtitle(\"ACF Plot for Globalization Index\")\n\n\n\n\n\nCode\nggPacf(global_ts)+ggtitle(\"PACF Plot for Globalization Index\")\n\n\n\n\n\nLooking at the ACF and PACF plots, we get a better understanding this time series. The ACF plot shows the present lag is significantly correlated with the first 12 years, after which it become significantly uncorrelated. Additionally, the PACF shows a stationary plot, due to the PACF values being contained in the significance bands. Thus, we can say that there is in fact strong autocorrelation in this time series data, however correlation is not present within the residuals.\n\n\nDickey-Fuller Test\n\n\nCode\nglobal_test &lt;- adf.test(global_ts)\nprint(global_test)\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  global_ts\nDickey-Fuller = 0.59021, Lag order = 3, p-value = 0.99\nalternative hypothesis: stationary\n\n\nThe Dickey-Fuller Test, with tests the alternative hypothesis that the time series is stationary, concluded a p-value of 0.99. Since 0.99 &gt; 0.05, we do not have enough evidence and thus, fail to rejec the null hypothesis, meaning that the time series object is not stationary.\n\n\nStationary:\nTherefore, in order to obtain stationary data to runs an ARMA and AMRIMA model on, we will need to compare differenced and detrended data to find which approach produces stationary data.\n\n\nCode\nfit = lm(global_ts~time(global_ts), na.action=NULL) \n\nplot1 &lt;- ggAcf(global_ts, 50, main=\"Original Data: Globalization Index\")\nplot2 &lt;- ggAcf(resid(fit), 50, main=\"Detrended data\") \nplot3 &lt;- ggAcf(diff(global_ts), 50, main=\"First Differenced Data\")\n\ngrid.arrange(plot1, plot2, plot3,ncol=3)\n\n\n\n\n\nFrom this plot, we can clearly see that the first differenced data results in a stationary plot, with the ACF values inside the significance bands. Since the first difference was able to coerce the data to be stationary, we can also say that the original data was linearly trended. Thus, moving forward, we will use first differencing on the globalization index in order to model this value."
  },
  {
    "objectID": "eda.html#stock-prices-looking-at-hybe-entertainment",
    "href": "eda.html#stock-prices-looking-at-hybe-entertainment",
    "title": "Exploratory Data Analysis",
    "section": "Stock Prices: Looking at HYBE Entertainment",
    "text": "Stock Prices: Looking at HYBE Entertainment\n\nTime Series plot:\nNext, since we saw, through the initial data visualization, the prevelance of Kpop and specifically BTS on the western music industry, we will take a look at HYBE stock prices through further time series EDA.\nPrimarily, we will clean our data such that missing dates corresponding to weekends and holidays where the stock market is closed will be estimated through exponential prediction. After which we will take the data and transform it into a time series object to plot.\n\n\nCode\noptions(\"getSymbols.warning4.0\"=FALSE)\noptions(\"getSymbols.yahoo.warning\"=FALSE)\n\n\nname &lt;- getSymbols('352820.KS', from = \"2019-01-01\", to = \"2023-09-01\")\nHYBE &lt;- data.frame(`352820.KS`$`352820.KS.Adjusted`)\nHYBE &lt;- HYBE %&gt;%\n  rownames_to_column(var = \"Date\") %&gt;%\n  mutate(Date = as.Date(Date)) %&gt;%\n  rename(Price = X352820.KS.Adjusted) %&gt;%\n  mutate(Price = Price/1352.60)\n\nstart_date &lt;- as.Date(\"2020-10-15\")\nend_date &lt;- as.Date(\"2023-09-01\")\n\nall_dates &lt;- data.frame(Date = seq(start_date, end_date, by = \"days\"))\n\nmerged_data &lt;- all_dates %&gt;%\n  left_join(HYBE, by = \"Date\")\n\nwrite.csv(merged_data, 'HYBE_cleaned_data.csv')\n\nimputed_time_series &lt;- na_ma(merged_data, k = 4, weighting = \"exponential\")\ndf_HYBE &lt;-data.frame(imputed_time_series)\ndf_HYBE$Date &lt;-as.Date(df_HYBE$Date,format = \"%Y-%m-%d\")\n\n# Create time series\nHYBE_ts &lt;-ts(df_HYBE$Price, star=decimal_date(as.Date(\"2020-10-15\", format = \"%Y-%m-%d\")), frequency = 365.25)\n\n# Create time series plot\nHYBE_plot &lt;- plot(as.ts(HYBE_ts), main = \"Time Series of HYBE Stock Prices\",\n                  xlab = 'Time', ylab = 'Price (USD)')\n\n\n\n\n\nUnlike the globalization index, the HYBE stock price fluctuates quite frequently in the smaller range of time. From 2021 to 2022, we can see a strong positive trend with slight seasonality. However, from 2022 onwards we see a sharp downward trend and with varying degrees of peaks. Thus, the uneven nature of the peaks and troughs results in data that is neither additive or multiplicative. Additionally, since the dataset is smaller, we cannot say anything of certain regarding cyclical patterns.\nNow, let’s look at the SMA graph for HYBE stock to identify potential crossings.\n\n\nMoving Average Smoothing:\n\n\nSMA Code\nHYBE_data = pd.read_csv('HYBE_cleaned_data.csv')\n\nHYBE_data.drop(HYBE_data.columns[0], axis=1, inplace = True)\nHYBE_data['Date'] = pd.to_datetime(HYBE_data['Date'])\nHYBE_data.dropna(axis  = 0, inplace = True)\n\nHYBE_data['3wma'] = HYBE_data['Price'].rolling(window = 15).mean()\nHYBE_data['20wma'] = HYBE_data['Price'].rolling(window = 100).mean()\nHYBE_data['50wma'] = HYBE_data['Price'].rolling(window = 250).mean()\n\nfig = px.line(HYBE_data, x='Date', y=['Price', '3wma', '20wma', '50wma'],\n              labels={'value': 'Daily Data', 'variable': 'Weekly Moving Average'},\n              title='Smoothing Moving Averages for HYBE Stock')\n\n# Show the plot\nfig.show()\n\n\n\n                        \n                                            \n\n\nThis plot depicts the smoothing moving average of HYBE stock prices. The smoothing windows I chose was 3-week, 20-week, and 50-week on the daily data. As we can see, the 3-week smoothing line is closely correlated with the actual prices, as expected. We can also see some crossings between the 3 smoothing moving averages. Primarily, we can see a crossing in September of 2021, where the 3-week SMA briefly crosses under and over the 20-week line. The crossing over of a shorter SMA, also called a golden cross, indicates that a postive trend in prices was to be expected, which is what occured. This is most likely due to the announcement of BTS performing at the 2021 Grammy Music Awards. Additionally, we can see a significant crossing again in April of 2022. This is when the 3-week and 20-week line cross under the 50-week. When a shorter term SMA cross under the longer SMA, we can infer a drop in stock prices, also called a Death Cross. This inevitably did happen, most likely due to talk of BTS’s enlistment into the Korean military as a part of mandatory service, which was officially announced June of that year.\nNext, let’s take a look at a few lag plots of data on itself as well ACF and PACF in order to identify possible signs of stationarity.\n\n\nLag-plot:\n\n\nCode\ngglagplot(HYBE_ts, do.lines=FALSE)+\n  ggtitle(\"Lag Plot for HYBE Stock Prices\")+\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n\n\n\n\n\nThese lag plots show similar results to that of the globalization index. The forst four lags have a very strong positive linear correlation, suggesting autocorrelation amongst those lags. From lag 5 onwards, we still see a string linear correlation, however we can also see a small circular pattern forming in the lag plots, suggesting a possibility of single-cycle sinusodial data.\n\n\nACF & PACF:\n\n\nCode\nggAcf(HYBE_ts, lag.max = 30)+ggtitle(\"ACF Plot for HYBE Stock Prices\")\n\n\n\n\n\nCode\nggPacf(HYBE_ts, lag.max = 30)+ggtitle(\"PACF Plot for HYBE Stock Prices\")\n\n\n\n\n\nSimilar to the globalization index, the ACF plot shows the present lag is significantly correlated with all other present lags in the plot, since all values are well above the siginificance bands. Additionally, the PACF shows a stationary plot, due to the PACF values being contained in the significance bands. Thus, we can say that there is in fact strong autocorrelation in this time series data, however correlation is not present within the residuals.\n\n\nDickey-Fuller Test:\n\n\nCode\nHYBE_test &lt;- adf.test(HYBE_ts)\nprint(HYBE_test)\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  HYBE_ts\nDickey-Fuller = -2.0109, Lag order = 10, p-value = 0.5737\nalternative hypothesis: stationary\n\n\nThe Dickey-Fuller Test resulted in a p-value of 0.5737. Since 0.5737 &gt; 0.05, we can fail to reject the null hypothesis and say that the time series object is not stationary.\n\n\nStationary:\nGiven that the original data is not stationary through the Dickey-Fuller test, we will use the detrending and differencing methods to coerse the data to become stationary.\n\n\nCode\nfit = lm(HYBE_ts~time(HYBE_ts), na.action=NULL) \n\nplot1 &lt;- ggAcf(HYBE_ts, lag.max = 30, main=\"Original Data: HYBE Stock Prices\")\nplot2 &lt;- ggAcf(resid(fit), lag.max = 30, main=\"Detrended data\") \nplot3 &lt;- ggAcf(diff(HYBE_ts), lag.max = 30, main=\"First Differenced Data\")\n\ngrid.arrange(plot1, plot2, plot3, ncol=3)\n\n\n\n\n\nHowever, after trying both detrending and first difference methods, both result in ACF plots showing autocorrelation and non-stationary tendencies. Thus, we will try the second differencing approach.\n\n\nCode\nplot4 &lt;- ggAcf(diff(diff(HYBE_ts)), lag.max = 30, main=\"Second Differenced Data\")\nplot4\n\n\n\n\n\nWith the second difference, we were able to get the HYBE stock prices to become stationary. Therefore, we could also suggest the original data has quadratic trending behavior.\nThus, going forward, we can use the second difference of the HYBE stock prices for modeling."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DSAN 5600: Time Series",
    "section": "",
    "text": "What is a Time Series ?\n\nAny metric that is measured over regular time intervals makes a Time Series. A time series is a sequence of data points or observations collected or recorded over a period of time at specific, equally spaced intervals. Each data point in a time series is associated with a particular timestamp or time period, making it possible to analyze and study how a particular variable or phenomenon changes over time. Time series data can be found in various domains and can represent a wide range of phenomena, including financial data, economic indicators, weather measurements, stock prices, sales figures, and more.\n\nExample: Weather data, Stock prices, Industry forecasts, etc are some of the common ones.\n\nThe analysis of experimental data that have been observed at different points in time leads to new and unique problems in statistical modeling and inference.\nThe obvious correlation introduced by the sampling of adjacent points in time can severely restrict the applicability of the many conventional statistical methods traditionally dependent on the assumption that these adjacent observations are independent and identically distributed.\n\nKey characteristics of time series data include:\nTemporal Order: Time series data is ordered chronologically, with each data point representing an observation at a specific point in time. The order of data points is critical for understanding trends and patterns over time.\nEqually Spaced Intervals: In most cases, time series data is collected at regular intervals, such as hourly, daily, weekly, monthly, or yearly. However, irregularly spaced time series data can also exist.\nDependency: Time series data often exhibits temporal dependency, meaning that the value at a given time is influenced by or related to the values at previous times. This dependency can take various forms, including trends, seasonality. This serial correlation is called as autocorrelation.\nComponents: Time series data can typically be decomposed into various components, including:\nTrend: The long-term movement or direction in the data. Seasonality: Repeating patterns or cycles that occur at fixed intervals. Noise/Irregularity: Random fluctuations or variability in the data that cannot be attributed to the trend or seasonality.\nApplications: Time series data is widely used for various applications, including forecasting future values, identifying patterns and anomalies, understanding underlying trends, and making informed decisions based on historical data.\nAnalyzing time series data involves techniques like time series decomposition, smoothing, statistical modeling, and forecasting. This class will cover but not be limited to traditional time series modeling including ARIMA, SARIMA, the multivariate Time Series modeling including; ARIMAX, SARIMAX, and VAR models, Financial Time Series modeling including; ARCH, GARCH models, and E-GARCH, M-GARCH..ect, Bayesian structural time series (BSTS) models, Spectral Analysis and Deep Learning Techniques for Time Series. Researchers and analysts use software tools like Python, R, and specialized time series libraries to work with and analyze time series data effectively.\nTime series analysis is essential in fields such as finance, economics, epidemiology, environmental science, engineering, and many others, as it provides insights into how variables change over time and allows for the development of predictive models to forecast future trends and outcomes.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "data-vizes.html",
    "href": "data-vizes.html",
    "title": "Data Vizes in TS",
    "section": "",
    "text": "Problem 1:\nThis plot depicts the stock prices for large fashion companies pre and post the COVID-19 pandemic. The fashion brands included are Adidas, Christian Dior, H&M, Nike, Puma, and Ross. Looking a combination of high end and low end brands, we can see that all companies faced a massive downtick in price evaluations in March of 2020, signaling the announcement of the global COVID-19 pandemic. Something to point out is that Christian Dior had a spike in price around mid-2021, resulting in a high uptick compared to the other brands. I was unable to find a reason as to why this uptick occured, but we can assume it was due to the highend nature of the brand.\n\n\n\n\n\n\n\nProblem 2:\nThe following graph depicts the precipication in Washington D.C. from January 2021 - January 2022. The graph shows periodic spikes throughout the year, however, the most precipitation occured in the third quarter of the year, with the highest amount occuring on August 20, 2021 at 3.76. The driest part of the year was the last quarter.\n\n\n\n\n\n\n\n\nProblem 3:\nBelow, is a graph depicting the unemployement rate for women in the United States of America throughout the 2000’s. This data was sourced from FRED. From this graph we can see 2 major historical moments that caused women’s unemployement. The 2008 market crash caused the first steep incline in unemployment. However, the market was able to recover such that the women who did work were able to in the 2010’s. The next major event was the COVID-19 global pandemic. Due to a global shutdown, there was a major spike in unemployement. This may be due to several women also being mothers and needing to stay home for childcare as a result of childcare services being unavailable at the time.\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "introduction.html",
    "href": "introduction.html",
    "title": "Introduction",
    "section": "",
    "text": "Music as a representation of culture has been defined since the birth of human connection and communities for centuries. In the past few decades, we have seen a transformation in music listening and sharing, from physical records to digital purchases to modern day streaming. Specifically in the United States (U.S.), popular music has, for the most part, been contained to English speaking, American artists. In recent years, however, the rise of KPOP, through groups like BTS, becoming increasingly popular in Western markets, to the point where it is considered part of the Pop genre Wang. With this new found accessibility of KPOP music through streaming, there comes the question of how music listening and cultural exchange has changed in the U.S.\nWe can define such a question as the effect of KPOP on the Western Music Industry and the impacts of this on globalization as a whole. At the moment, there is literature to discuss both viewpoints of music globalization; the first being that streaming has expanded the average U.S. consumer’s music palette from traditional American music, while the second suggests that streaming has only narrowed the average listener’s taste through algorithmic suggestions and playlists Bello and Garcia (2021). Cultural Divergence in popular music suggests that while clustering in music tastes can be noted for specific regions of the world, we do see an “upward trend in music consumption diversity that started in 2017 and spans across platforms” Bello and Garcia (2021).\nHowever, in order to fully realize the question of KPOP’s effect on the western music industry through time, I propose analyzing the following: music charting on Billboard and iTunes, stock prices for music record companies, live music statistics and sales data, and quantifying globalization over time.\n\nThese four analytical venues will provide an in-depth analysis to further understand whether the trend of globalization of cultures has in fact translated to music listening and whether the average American has positive sentiment to this overall trend.\n\n\n\nWhen do we see a shift where the KPOP industry makes an impact on the western music industry?\nHow does music charting influence music created today?\nTo what extent has KPOP in the United States led to a positive or negative sentiment among the general population?\nHas KPOP changed the overall trends of popular music in America (i.e musical elements, danceability, etc.)?\nWhat combined conclusions can be drawn from the four analytical venues demonstrated in the big-ideas chart?\nGiven the impact of the KPOP concerts within the West, can a time-series analysis forecast future sales from KPOP artists?\nWhat are some long term trends in music stock prices?\nHow has the availability of KPOP music changed over time and how does that translate to globalization?\nAre there any cyclical trends present in popular genres within the United States in the past 10 years?\nIs the globalization of music in the U.S. simply a fad of our time or a product of technical advancements in music dispersion?"
  },
  {
    "objectID": "introduction.html#thought-provoking-questions",
    "href": "introduction.html#thought-provoking-questions",
    "title": "Introduction",
    "section": "",
    "text": "When do we see a shift where the KPOP industry makes an impact on the western music industry?\nHow does music charting influence music created today?\nTo what extent has KPOP in the United States led to a positive or negative sentiment among the general population?\nHas KPOP changed the overall trends of popular music in America (i.e musical elements, danceability, etc.)?\nWhat combined conclusions can be drawn from the four analytical venues demonstrated in the big-ideas chart?\nGiven the impact of the KPOP concerts within the West, can a time-series analysis forecast future sales from KPOP artists?\nWhat are some long term trends in music stock prices?\nHow has the availability of KPOP music changed over time and how does that translate to globalization?\nAre there any cyclical trends present in popular genres within the United States in the past 10 years?\nIs the globalization of music in the U.S. simply a fad of our time or a product of technical advancements in music dispersion?"
  },
  {
    "objectID": "data-visualization.html",
    "href": "data-visualization.html",
    "title": "Data Visualization",
    "section": "",
    "text": "The purpose of data visualization is to find possible trends, patterns, and anomalies within the datasets. Primarily, let’s take a look at globalization as a general topic through the lense of the KOF Globalization Index."
  },
  {
    "objectID": "data-visualization.html#kof-globalization",
    "href": "data-visualization.html#kof-globalization",
    "title": "Data Visualization",
    "section": "KOF Globalization",
    "text": "KOF Globalization\nThe KOF Globalization index quantifies globalization within a country through a multitude of lenses. We will be looking at the general globalization index values as well as technology, culture, and TV and Media, since it all correlates to sphere of music and music streaming in the modern world.\nThrough R, I cleaning the dataset from KOF and used Tableau to create interative global maps for each respective index system.\n\n\nCode\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(dplyr)\n\nglobal &lt;- read_excel(\"KOFGI_2022_public.xlsx\")\nglobal &lt;- global %&gt;%\n  select(code, country, year, KOFGI, KOFInGIdf, KOFInGIdj, KOFCuGIdf) %&gt;%\n  drop_na(c(KOFGI, KOFInGIdf, KOFInGIdj, KOFCuGIdf))\n\nwrite.csv(global, \"globalization.csv\", row.names=FALSE)\n\n\nFrom this cleaned data, we can visualize the globalization index over time for general globalization as well as indexes specifc to culture and entertainment.\nPlease allow for the visualization to load when moving the slider as it handles a large amount of data\n\n\n\n\n\n\n   \n\n\n\n\nFrom the graphs, we can a gradual increase in the globalization index over the past 50 years. Specifically, North America, Western Europe, and Australia have the highest globalization indexes across all index types throughout the 50 years. Additionally, we can see that in 1990, Russia’s globalization index was added, resulting in the world’s largest populous countries to be added to the index. Once we get to 2000, we continue to see the highest globalization values in North America, Western Europe (specifically UK and France), and Australia, with new additions like South Korea and Japan with higher values. By 2020, the aforementioned countries have even higher index values, most in the 80’s and 90’s out of 100. China, Russia, Brazil, and India are also most notable countries with very high globalization values, especially in the technology category."
  },
  {
    "objectID": "data-visualization.html#record-label-stocks",
    "href": "data-visualization.html#record-label-stocks",
    "title": "Data Visualization",
    "section": "Record Label Stocks:",
    "text": "Record Label Stocks:\nNext, in order to better understand globalization within the music industry, we will take a look at large record label stock prices over time. I chose the most popular record labels who house some of the largest musicians in the industry.\n\nUniversal Music Group Inc. (UMGP)\nWarner Music Group Corp. (WMG)\nHYBE Co. (352820.KS)\nSM Entertainment (041510.KQ)\nYG Entertainment (122870.KQ)\nJYP Entertainment (035900.KQ)\n\nI used plotly in R to show this interactive line plot.\n\n\nCode\nlibrary(plotly)\nlibrary(quantmod)\n\noptions(\"getSymbols.warning4.0\"=FALSE)\noptions(\"getSymbols.yahoo.warning\"=FALSE)\n\ntickers = c(\"UMGP\", \"WMG\", \"352820.KS\", \"041510.KQ\", '122870.KQ', '035900.KQ')\n\nfor (i in tickers){\n  getSymbols(i, from = \"2000-01-01\", to = \"2023-09-01\")\n}\n\nUMGP &lt;- data.frame(UMGP$UMGP.Adjusted)\nUMGP &lt;- UMGP %&gt;%\n  rownames_to_column(var = \"Date\") %&gt;%\n  mutate(Date = as.Date(Date)) %&gt;%\n  rename(Price = UMGP.Adjusted)\n\nWMG &lt;- data.frame(WMG$WMG.Adjusted)\nWMG &lt;- WMG %&gt;%\n  rownames_to_column(var = \"Date\") %&gt;%\n  mutate(Date = as.Date(Date)) %&gt;%\n  rename(Price = WMG.Adjusted)\n\nHYBE &lt;- data.frame(`352820.KS`$`352820.KS.Adjusted`)\nHYBE &lt;- HYBE %&gt;%\n  rownames_to_column(var = \"Date\") %&gt;%\n  mutate(Date = as.Date(Date)) %&gt;%\n  rename(Price = X352820.KS.Adjusted) %&gt;%\n  mutate(Price = Price/1352.60)\n\nSM &lt;- data.frame(`041510.KQ`$`041510.KQ.Adjusted`)\nSM &lt;- SM %&gt;%\n  rownames_to_column(var = \"Date\") %&gt;%\n  mutate(Date = as.Date(Date)) %&gt;%\n  rename(Price = X041510.KQ.Adjusted) %&gt;%\n  mutate(Price = Price/1352.60)\n\nYG &lt;- data.frame(`122870.KQ`$`122870.KQ.Adjusted`)\nYG &lt;- YG %&gt;%\n  rownames_to_column(var = \"Date\") %&gt;%\n  mutate(Date = as.Date(Date)) %&gt;%\n  rename(Price = X122870.KQ.Adjusted) %&gt;%\n  mutate(Price = Price/1352.60)\n\nJYP &lt;- data.frame(`035900.KQ`$`035900.KQ.Adjusted`)\nJYP &lt;- JYP %&gt;%\n  rownames_to_column(var = \"Date\") %&gt;%\n  mutate(Date = as.Date(Date)) %&gt;%\n  rename(Price = X035900.KQ.Adjusted) %&gt;%\n  mutate(Price = Price/1352.60)\n\nstock_dataframes &lt;- list(UMGP, WMG, HYBE, SM, YG, JYP)\nstock_names &lt;- list(\"UMGP\", \"WMG\", \"HYBE\", \"SM\", \"YG\", \"JYP\")\np &lt;- plot_ly()\n\n# Add traces for each stock to the plot\nfor (i in 1:length(stock_dataframes)) {\n  stock_df &lt;- stock_dataframes[[i]]\n  p &lt;- add_trace(p, x = stock_df$Date, y = stock_df$Price, mode = 'lines', name = stock_names[i])\n}\n\n# Customize the layout if needed\np &lt;- layout(p, title = \"Stock Prices of Music Record Label\", xaxis = list(title = \"Date\"), yaxis = list(title = \"Price (USD)\"))\n\n# Show the plot\np\n\n\n\n\n\n\nFrom the line plot, we can analyze these record labels as they enter the market to today. Starting with the oldest public record label, SONY seems to have a seasonal downward trend from 2000 - 2001, however that quickly ends to a more irregular and constant movement. We can see a large spike again in the early 2022, possibly due to SONY’s press release for the vison-s suv, a self driving car Lawler (2022). Of the other stocks, a notable one to note is the introduction of HYBE Co. in late 2020. HYBE, a South Korean Entertainment company, founded by Bang Shi Hyuk, is notable for its creation of the current largest boy band in the industy, BTS. With their international Billboard Hot 100 #1 song, Dynamite, releasing in August of 2020, the band a stirred enough interest for the company’s entrance in the market to be a success at $188 USD. The price reached a high in November of 2021 at $306 USD, most likely due to BTS’s Artist of the Year award at the 2021 American Music Awards and their Grammy nomination. However, since that peak, the price has gone down significantly in June of 2022, likely a result of the company’s largest artists, BTS, announcing a hiatus of group activities due to military enlistment “HYBE Shares Rise as World Contemplates Company Sans BTS” (2022). Amonst the remaining tickers, we can a gradual positive trend with no seasonality and a slight spike around early 2022, as artists were announcing in person activities after the Covid-19 pandemic. Thus, we can see through these stock prices that while American record companies seem to a large and consistent history in the market, new companies like HYBE and SM from South Korea have started to take space in the public markets."
  },
  {
    "objectID": "data-visualization.html#billboard-charts",
    "href": "data-visualization.html#billboard-charts",
    "title": "Data Visualization",
    "section": "Billboard Charts:",
    "text": "Billboard Charts:\nThe Billboard Hot 100 is a chart created by billboard used to rank the top 100 songs in the United States per week. In order to see the trends in musical globalization, I will be taking a look artists who acheived number 1’s on the Billboard Hot 100 and the number of weeks those songs stayed on the chart from 2010 - 2021. I used Tableau to show this interactive bubble graph.\n\n\nCode\ncharts &lt;- read_csv('charts.csv')\ncharts &lt;- charts %&gt;%\n  filter(rank == 1) %&gt;%\n  select(-`last-week`, -`peak-rank`)\n\nwrite.csv(charts, \"number1_charts.csv\", row.names=FALSE)\n\n\n\n\n\n\n\n\n    \n\n\n\n\nFrom this visualization we notice that first instance of a non-Western artist debuting at number 1 on the Billboard Hot 100 is in 2017 with Luis Fonsi, Daddy Yankee, and Justin Bieber with Despacito. The song stayed on the charts for 78 weeks, being song with the most weeks on the Billboard Hot 100 in this timeframe. The next non-Western artist would be BTS, as mentioned previously, with their song Dynamite, first debuting number one in September of 2020. BTS appears again in June 2021, with their song Butter which stayed on the charts for 15 weeks. Latin Artists Bad Bunny and J Balvin also made a debut on the charts at number 1 with the song I Like It along side Cardi B for a total of 12 weeks on the charts. Thus, we can see that after 2015, we saw an increaing number of number 1’s from non-Western artists on the America charts, a sign of general positive feedback from the public regarding the globalization of music."
  },
  {
    "objectID": "data-visualization.html#spotify-data",
    "href": "data-visualization.html#spotify-data",
    "title": "Data Visualization",
    "section": "Spotify Data:",
    "text": "Spotify Data:\nLastly, we will take another look at Spotify Data in order to analyze music trends from popular Non-Western artists and popular Western artists. This small example shows energy over time between artists BTS, Taylor Swift, and Daddy Yankee.\n\n\nCode\nlibrary(ggplot2)\nlibrary(knitr)\nlibrary(spotifyr)\nlibrary(dplyr)\nlibrary(lubridate)\nlibrary(plotly)\n\nSys.setenv(SPOTIFY_CLIENT_ID = \"48875e31f589401f83c6bd43005d94f7\")\nSys.setenv(SPOTIFY_CLIENT_SECRET = \"d215e4ea690d4b9b9c1c5e0afbb113a5\")\n\naccess_token &lt;- get_spotify_access_token()\nartists &lt;- c(\"BTS\", \"Taylor Swift\", \"Daddy Yankee\")\n\nBTS &lt;- get_artist_audio_features(\"BTS\")\nBTS_A &lt;- data.frame(BTS$artist_name,\nBTS$instrumentalness,\nBTS$valence,\nBTS$danceability,\nBTS$energy,\nBTS$loudness,\nBTS$speechiness,\nBTS$acousticness,\nBTS$liveness,\nBTS$tempo,\nBTS$track_name,\nBTS$album_name,\nBTS$album_release_year,\nBTS$album_release_date)\n\ncolnames(BTS_A) &lt;- c(\"artist_name\",\"instrumentalness\",\"Valence\",\"danceability\",\"energy\",\n\"loudness\",\"speechiness\",\"acousticness\",\"liveness\",\n\"tempo\",\"track_name\",\"album_name\",\"album_release_year\",\"date\")\n\nTaylor_Swift &lt;- get_artist_audio_features(\"Taylor Swift\")\nTaylor_Swift_A &lt;- data.frame(Taylor_Swift$artist_name,\nTaylor_Swift$instrumentalness,\nTaylor_Swift$valence,\nTaylor_Swift$danceability,\nTaylor_Swift$energy,\nTaylor_Swift$loudness,\nTaylor_Swift$speechiness,\nTaylor_Swift$acousticness,\nTaylor_Swift$liveness,\nTaylor_Swift$tempo,\nTaylor_Swift$track_name,\nTaylor_Swift$album_name,\nTaylor_Swift$album_release_year,\nTaylor_Swift$album_release_date)\n\ncolnames(Taylor_Swift_A) &lt;- c(\"artist_name\",\"instrumentalness\",\"Valence\",\"danceability\",\"energy\",\n\"loudness\",\"speechiness\",\"acousticness\",\"liveness\",\n\"tempo\",\"track_name\",\"album_name\",\"album_release_year\",\"date\")\n\n\nDaddy_Yankee &lt;- get_artist_audio_features(\"Daddy Yankee\")\nDaddy_Yankee_A &lt;- data.frame(Daddy_Yankee$artist_name,\nDaddy_Yankee$instrumentalness,\nDaddy_Yankee$valence,\nDaddy_Yankee$danceability,\nDaddy_Yankee$energy,\nDaddy_Yankee$loudness, \nDaddy_Yankee$speechiness,\nDaddy_Yankee$acousticness,\nDaddy_Yankee$liveness,\nDaddy_Yankee$tempo,\nDaddy_Yankee$track_name,\nDaddy_Yankee$album_name,\nDaddy_Yankee$album_release_year,\nDaddy_Yankee$album_release_date)\n\ncolnames(Daddy_Yankee_A) &lt;- c(\"artist_name\",\"instrumentalness\",\"Valence\",\"danceability\",\"energy\",\n\"loudness\",\"speechiness\",\"acousticness\",\"liveness\",\n\"tempo\",\"track_name\",\"album_name\",\"album_release_year\",\"date\")\n\nartists &lt;- rbind(BTS_A, Taylor_Swift_A, Daddy_Yankee_A)\nartists$date &lt;- as.Date(artists$date, format = \"%Y-%m-%d\")\n\nfig &lt;- plot_ly(artists, x = ~date, y = ~energy, color = ~artist_name, \n               type = 'scatter', mode = 'markers', size = ~speechiness) \n\nfig &lt;- fig %&gt;% layout(xaxis = list(title = \"Album Released Date\"),\n                      yaxis = list(title =\"Energy\"), \n                      title = \"Energy - Taylor Swift/BTS/Daddy Yankee\")\n\nfig\n\n\n\n\n\n\nSimilar to the visualization in Data Sources, we can see that with both BTS and Daddy Yankee, energy is consistently very high throughout their careers, with fewer spread in comparison to Taylor Swift. This can indicate that, especially as musical globalization begins to shape the American music industry, we can see an influx in high energy songs, similar to successful non-Western acts like BTS and Daddy Yankee, across genres as shown with the juxtaposition of Taylor Swift, who has a larger spread of energy throughout her discography."
  }
]