{"title":"Exploratory Data Analysis","markdown":{"yaml":{"title":"Exploratory Data Analysis"},"headingText":"Globalization","containsRefs":false,"markdown":"\n\nExploratory Data Analysis (EDA) for time series involves a systematic process to uncover patterns, trends, and underlying characteristics within the data. The initial step often includes a fundamental Time Series Plot, providing a visual representation of data points over time. Next, plotting the Simple Moving Average (SMA) aids in smoothing fluctuations and revealing long-term trends. Lag plots help identify localized patterns and autocorrelations within the time series, providing insights into potential cyclical behavior.\n\nThe examination of Autocorrelation Function (ACF) and Partial Autocorrelation Function (PACF) plots further refines our understanding of temporal dependencies and the need for differencing. This step is crucial in selecting appropriate parameters for time series models.\n\nIn addition to the ACF & PACF plots, the Dickey-Fuller Test is employed to identify stationarity. This statistical test evaluates whether a time series possesses a unit root, indicative of non-stationarity. A stationary time series exhibits consistent statistical properties over time, making it useful for modeling. \n\nThe purpose of EDA for our analysis is to confirm our univariate time series data is stationary prior to modeling. In our case, we will be performing EDA on the KOF globalization index, the record label of greatest interest, HYB Co., and the inbound passengers to South Korea. \n\n---\n\n```{r}\n#| code-fold: true\n#| code-summary: 'Importing Libraries'\n#| warning: false\n#| output: false\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(forecast)\nlibrary(astsa) \nlibrary(xts)\nlibrary(tseries)\nlibrary(fpp2)\nlibrary(fma)\nlibrary(lubridate)\nlibrary(tidyverse)\nlibrary(TSstudio)\nlibrary(quantmod)\nlibrary(tidyquant)\nlibrary(plotly)\nlibrary(ggplot2)\nlibrary(imputeTS)\nlibrary(gridExtra)\nlibrary(reticulate)\nlibrary(readxl)\nuse_python(\"/usr/local/bin/python3\", require = T)\nknitr::knit_engines$set(python = reticulate::eng_python)\npy_install(\"tensorflow\")\n```\n\n\n\n::: {.panel-tabset}\n\n## Time Series plot\n```{r}\n#| warning: false\n#| code-fold: true\n\n# Import dataset\nglobal <- read_csv('cleaned_data/globalization.csv')\n\n# Filter information\nglobal <- global %>%\n  filter(country == 'United States') %>%\n  select(year, KOFGI) %>%\n  mutate(year = as.Date(year))\n\n# Create time series\nglobal_ts <-ts(global$KOFGI, star=decimal_date(as.Date(\"1970-01-01\", format = \"%Y-%m-%d\")), frequency = 1)\n\n# Create time series plot\nglobal_plot <- plot(as.ts(global_ts), main = \"Time Series of KOF Globalization Index within the United States\",\n                  xlab = 'Time', ylab = 'KOF Index')\n\n# Show plot\nggplotly(global_plot)\n\n```\n  \n\n## Moving Average Smoothing \n```{python}\n#| code-fold: true\n#| code-summary: 'SMA Code'\n#| warning: false\n\n\nimport pandas as pd\nimport datetime\nimport plotly \nfrom datetime import datetime \nfrom pandas_datareader import data as pdr\nimport plotly.offline as pyo\nimport plotly.graph_objects as go \nfrom plotly.subplots import make_subplots\nimport plotly.express as px\n\nglobal_data = pd.read_csv('cleaned_data/globalization.csv')\nglobal_data = global_data[global_data['country'] == 'United States']\nglobal_data['year'] = pd.to_datetime(global_data['year'], format='%Y')\n\nglobal_data['5yma'] = global_data['KOFGI'].rolling(window = 5).mean()\nglobal_data['10yma'] = global_data['KOFGI'].rolling(window = 10).mean()\nglobal_data['20yma'] = global_data['KOFGI'].rolling(window = 20).mean()\n\nfig = px.line(global_data, x='year', y=['KOFGI', '5yma', '10yma', '20yma'],\n              labels={'value': 'Yearly Data', 'variable': 'Moving Average'},\n              title='Yearly Data and Moving Averages for the Globalization Index')\n\n# Show the plot\nfig.show()\n```\n\n## Lag-plot \n```{r}\n#| warning: false\n#| code-fold: true\ngglagplot(global_ts, do.lines=FALSE)+ggtitle(\"Lag Plot for the KOF Globalization Index\")\n```\n\n## ACF & PACF \n```{r}\n#| warning: false\n#| code-fold: true\nggAcf(global_ts)+ggtitle(\"ACF Plot for Globalization Index\")\nggPacf(global_ts)+ggtitle(\"PACF Plot for Globalization Index\")\n```\n\n## Dickey-Fuller Test\n```{r}\n#| warning: false\n#| code-fold: true\nglobal_test <- adf.test(global_ts)\nprint(global_test)\n```\n\n## Stationary \n```{r}\n#| warning: false\n#| code-fold: true\nfit = lm(global_ts~time(global_ts), na.action=NULL) \n\nplot1 <- ggAcf(global_ts, 50, main=\"Original Data: Globalization Index\")\nplot2 <- ggAcf(resid(fit), 50, main=\"Detrended data\") \nplot3 <- ggAcf(diff(global_ts), 50, main=\"First Differenced Data\")\n\ngrid.arrange(plot1, plot2, plot3,ncol=3)\n```\n\n:::\n\nLet's begin by anaylzing globalization of the United States from 1970 to 2022. I will be using the general globalization index for this time series anaylsis. First I will begin by filtering the data and creating a time series object in R. This will allow us to **plot the time series** data for initial analysis.\n\nFrom the plot of the globalization index in the United States, we can see a strong positive upward trend. In terms of seasonality and cyclic patterns, we are unable to see such patterns in the data. Additionally, we can see very slight peaks in the data in 1986 and 2009, however, they are not enough to conclude any patterns of interest. Thus,we can say this plot is neither additive nor multiplicative. \n\nNext, we'll take a look at a **moving average smoothing** plot to obtain some information on potential crossings. \n\nThe plot shows us the smoothing moving average for the yearly KOF globalization index data. The three types of smoothing I chose was 5-year, 10-year, and 20-year moving averages. As we can see in the graph, all smoothing lines show a positive upward trend across the time interval (the past 50 years). There is also no crossing between the smoothing lines, possibly indicating that the data had a constant upward trend with no seasonality or cyclical trends throughout. \n\nNext, let's take a look at a few **lag plots** of data on itself as well ACF and PACF in order to identify possible signs of stationarity. \n\nWe can see in lags 1,2, and 3 a very strong positive linear relationship, meaning a positive autocorrelation in the lags. From lag 4 and onward, the trend is still strongly positive, but less linear, suggesting a weaker autocorrelation. We also don't see any groupings in the lags, suggesting that there is no seasonality in the data. \n\nLooking at the **ACF and PACF** plots, we get a better understanding this time series. The ACF plot shows the present lag is significantly correlated with the first 12 years, after which it become significantly uncorrelated. Additionally, the PACF shows a stationary plot, due to the PACF values being contained in the significance bands. Thus, we can say that there is in fact strong autocorrelation in this time series data, however correlation is not present within the residuals. \n\nThe **Dickey-Fuller Test**, which tests the alternative hypothesis that the time series is stationary, returned a p-value of 0.99. Since 0.99 > 0.05, we do not have enough evidence and thus, fail to reject the null hypothesis, meaning that the time series object is not stationary. However, since we got different results from the ACF and PACF, we'll proceed with the ACF results and difference/detrend the data.  \n\nTherefore, in order to obtain stationary data to runs an ARMA and AMRIMA model on, we will need to compare **differenced and detrended** data to find which approach produces stationary data. \n\nFrom this plot, we can clearly see that the first differenced data results in a stationary plot, with the ACF values inside the significance bands. Since the first difference was able to coerce the data to be stationary, we can also say that the original data was linearly trended. Thus, moving forward, we will use first differencing on the globalization index in order to model this value. \n\n---\n\n## Stock Prices: Looking at HYBE Entertainment\n\n::: {.panel-tabset}\n\n## Time Series plot \n```{r}\n#| warning: false\n#| code-fold: true\noptions(\"getSymbols.warning4.0\"=FALSE)\noptions(\"getSymbols.yahoo.warning\"=FALSE)\n\n\nname <- getSymbols('352820.KS', from = \"2019-01-01\", to = \"2023-09-01\")\nHYBE <- data.frame(`352820.KS`$`352820.KS.Adjusted`)\nHYBE <- HYBE %>%\n  rownames_to_column(var = \"Date\") %>%\n  mutate(Date = as.Date(Date)) %>%\n  rename(Price = X352820.KS.Adjusted) %>%\n  mutate(Price = Price/1352.60)\n\nstart_date <- as.Date(\"2020-10-15\")\nend_date <- as.Date(\"2023-09-01\")\n\nall_dates <- data.frame(Date = seq(start_date, end_date, by = \"days\"))\n\nmerged_data <- all_dates %>%\n  left_join(HYBE, by = \"Date\")\n\nimputed_time_series <- na_ma(merged_data, k = 4, weighting = \"exponential\")\ndf_HYBE <-data.frame(imputed_time_series)\ndf_HYBE$Date <-as.Date(df_HYBE$Date,format = \"%Y-%m-%d\")\n\nwrite.csv(df_HYBE, 'cleaned_data/HYBE_cleaned_data.csv')\n\n# Create time series\nHYBE_ts <-ts(df_HYBE$Price, star=decimal_date(as.Date(\"2020-10-15\", format = \"%Y-%m-%d\")), frequency = 365.25)\n\n# Create time series plot\nHYBE_plot <- plot(as.ts(HYBE_ts), main = \"Time Series of HYBE Stock Prices\",\n                  xlab = 'Time', ylab = 'Price (USD)')\n```\n\n## Moving Average Smoothing \n```{python}\n#| code-fold: true\n#| code-summary: 'SMA Code'\n#| warning: false\nHYBE_data = pd.read_csv('cleaned_data/HYBE_cleaned_data.csv')\n\nHYBE_data.drop(HYBE_data.columns[0], axis=1, inplace = True)\nHYBE_data['Date'] = pd.to_datetime(HYBE_data['Date'])\nHYBE_data.dropna(axis  = 0, inplace = True)\n\nHYBE_data['3wma'] = HYBE_data['Price'].rolling(window = 15).mean()\nHYBE_data['20wma'] = HYBE_data['Price'].rolling(window = 100).mean()\nHYBE_data['50wma'] = HYBE_data['Price'].rolling(window = 250).mean()\n\nfig = px.line(HYBE_data, x='Date', y=['Price', '3wma', '20wma', '50wma'],\n              labels={'value': 'Daily Data', 'variable': 'Weekly Moving Average'},\n              title='Smoothing Moving Averages for HYBE Stock')\n\n# Show the plot\nfig.show()\n```\n\n## Lag-plot\n```{r}\n#| warning: false\n#| code-fold: true\ngglagplot(HYBE_ts, do.lines=FALSE)+\n  ggtitle(\"Lag Plot for HYBE Stock Prices\")+\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n```\n\n## ACF & PACF\n```{r}\n#| warning: false\n#| code-fold: true\nggAcf(HYBE_ts, lag.max = 30)+ggtitle(\"ACF Plot for HYBE Stock Prices\")\nggPacf(HYBE_ts, lag.max = 30)+ggtitle(\"PACF Plot for HYBE Stock Prices\")\n```\n\n## Dickey-Fuller Test\n```{r}\n#| warning: false\n#| code-fold: true\nHYBE_test <- adf.test(HYBE_ts)\nprint(HYBE_test)\n```\n\n## Stationary\n```{r}\n#| warning: false\n#| code-fold: true\nfit = lm(HYBE_ts~time(HYBE_ts), na.action=NULL) \n\nplot1 <- ggAcf(HYBE_ts, lag.max = 30, main=\"Original Data: HYBE Stock Prices\")\nplot2 <- ggAcf(resid(fit), lag.max = 30, main=\"Detrended data\") \nplot3 <- ggAcf(diff(HYBE_ts), lag.max = 30, main=\"First Differenced Data\")\n\ngrid.arrange(plot1, plot2, plot3, ncol=3)\n```\n\n```{r}\n#| warning: false\n#| code-fold: true\nplot4 <- ggAcf(diff(diff(HYBE_ts)), lag.max = 30, main=\"Second Differenced Data\")\nplot4\n```\n\n::: \n\nNext, since we saw, through the initial data visualization, the prevelance of KPOP, and specifically BTS, on the western music industry, we will take a look at HYBE stock prices through further time series EDA. \n\nPrimarily, we will clean our data such that missing dates corresponding to weekends and holidays where the stock market is closed will be estimated through exponential prediction. After which we will take the data and transform it into a **time series object to plot**.\n\nUnlike the globalization index, the HYBE stock price fluctuates quite frequently in the smaller range of time. From 2021 to 2022, we can see a strong positive trend with slight seasonality. However, from 2022 onwards we see a sharp downward trend and with varying degrees of peaks. Thus, the uneven nature of the peaks and troughs results in data that is neither additive or multiplicative. Additionally, since the dataset is smaller, we cannot say anything of certain regarding cyclical patterns. \n\nNow, let's look at the **SMA graph** for HYBE stock to identify potential crossings. \n\nThis plot depicts the smoothing moving average of HYBE stock prices. The smoothing windows I chose was 3-week, 20-week, and 50-week on the daily data. As we can see, the 3-week smoothing line is closely correlated with the actual prices, as expected. We can also see some crossings between the 3 smoothing moving averages. Primarily, we can see a crossing in September of 2021, where the 3-week SMA briefly crosses under and over the 20-week line. The crossing over of a shorter SMA, also called a golden cross, indicates that a postive trend in prices was to be expected, which is what occured. This is most likely due to the announcement of BTS performing at the 2021 Grammy Music Awards. Additionally, we can see a significant crossing again in April of 2022. This is when the 3-week and 20-week line cross under the 50-week. When a shorter term SMA cross under the longer SMA, we can infer a drop in stock prices, also called a Death Cross. This inevitably did happen, most likely due to talk of BTS's enlistment into the Korean military as a part of mandatory service, which was officially announced June of that year. \n\nNext, let's take a look at a few **lag plots** of data on itself as well ACF and PACF in order to identify possible signs of stationarity. \n\nThese lag plots show similar results to that of the globalization index. The forst four lags have a very strong positive linear correlation, suggesting autocorrelation amongst those lags. From lag 5 onwards, we still see a string linear correlation, however we can also see a small circular pattern forming in the lag plots, suggesting a possibility of single-cycle sinusodial data. \n\nLooking at the **ACF & PACF** plots, the ACF plot shows the present lag is significantly correlated with all other present lags in the plot, since all values are well above the siginificance bands. Additionally, the PACF shows a stationary plot, due to the PACF values being contained in the significance bands. Thus, we can say that there is in fact strong autocorrelation in this time series data, however correlation is not present within the residuals. \n\nThe **Dickey-Fuller Test** resulted in a p-value of 0.5737. Since 0.5737 > 0.05, we can fail to reject the null hypothesis and say that the time series object is not stationary. However, since we got different results from the ACF and PACF, we'll proceed with the ACF results and difference/detrend the data. \n\nHowever, after trying both **detrending and first difference** methods, both result in ACF plots showing autocorrelation and non-stationary tendencies. Thus, we will try the second differencing approach. \n\nWith the second difference, we were able to get the HYBE stock prices to become stationary. Therefore, we could also suggest the original data has quadratic trending behavior. \n\nThus, going forward, we can use the second difference of the HYBE stock prices for modeling.\n\n---\n\n## Korean Tourism\n\n::: {.panel-tabset}\n\n## Time Series Plot\n```{r}\n#| warning: false\n#| code-fold: true\nsk_passengers <- read_xlsx('raw_data/sk_passenger_arrivals.xlsx')\n\nsk_passengers <- sk_passengers %>%\n  unite(date, year, month, sep = '-') %>%\n  mutate(date = as.Date(paste(date, '01', sep = '-'))) %>%\n  filter(year(date) < 2020) #In order to avoid the anomaly of the 2020 pandemic\n\nwrite.csv(sk_passengers, \"cleaned_data/air_passengers_cleaned.csv\")\n\nair_travel_ts <- ts(sk_passengers$Passengers, start = c(2010, 10), \n                    frequency = 12)\n\nautoplot(air_travel_ts)+ggtitle(\"Air passenger arrivals to Incheon Airport (SK)\") \n```\n\n## Moving Average Smoothing \n```{python}\n#| code-fold: true\n#| code-summary: 'SMA Code'\n#| warning: false\n\nimport pandas as pd\nimport datetime\nimport plotly \nfrom datetime import datetime \nfrom pandas_datareader import data as pdr\nimport plotly.offline as pyo\nimport plotly.graph_objects as go \nfrom plotly.subplots import make_subplots\nimport plotly.express as px\n\nglobal_data = pd.read_csv('cleaned_data/air_passengers_cleaned.csv')\nglobal_data['date'] = pd.to_datetime(global_data['date'], format='%Y-%m')\n\nglobal_data['6mma'] = global_data['Passengers'].rolling(window = 6).mean()\nglobal_data['12mma'] = global_data['Passengers'].rolling(window = 12).mean()\nglobal_data['36mma'] = global_data['Passengers'].rolling(window = 36).mean()\n\nfig = px.line(global_data, x='date', y=['Passengers', '6mma', '12mma', '36mma'],\n              labels={'value': 'Monthly Data', 'variable': 'Moving Average'},\n              title='Monthly Data and Moving Averages for the Inbound Passengers to SK')\n\n# Show the plot\nfig.show()\n```\n\n## Lag-plot\n```{r}\n#| warning: false\n#| code-fold: true\ngglagplot(air_travel_ts, do.lines=FALSE)+\n  ggtitle(\"Lag Plot for Inbound Passengers to SK\")+\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n\ngglagplot(air_travel_ts, do.lines=FALSE, set.lags = c(12, 24, 36, 48))+\n  ggtitle(\"Air passenger arrivals to Incheon Airport (SK)\") \n```\n\n## ACF & PACF\n```{r}\n#| warning: false\n#| code-fold: true\nggAcf(air_travel_ts, lag.max = 30)+ggtitle(\"ACF Plot for Inbound Passengers to SK\")\nggPacf(air_travel_ts, lag.max = 30)+ggtitle(\"PACF Plot for Inbound Passengers to SK\")\n```\n\n## Dickey-Fuller Test\n```{r}\n#| warning: false\n#| code-fold: true\npassengers_test <- adf.test(air_travel_ts)\nprint(passengers_test)\n```\n\n## Stationary\n```{r}\n#| warning: false\n#| code-fold: true\nfit = lm(air_travel_ts~time(air_travel_ts), na.action=NULL) \n\nplot1 <- ggAcf(air_travel_ts, lag.max = 30, main=\"Original Data: Inbound Passengers to SK\")\nplot2 <- ggAcf(resid(fit), lag.max = 30, main=\"Detrended data\") \nplot3 <- ggAcf(diff(air_travel_ts), lag.max = 30, main=\"First Differenced Data\")\n\ngrid.arrange(plot1, plot2, plot3, ncol=3)\n```\n\n```{r}\n#| warning: false\n#| code-fold: true\nplot4 <- ggAcf(air_travel_ts %>% diff(12), lag.max = 30, main=\"Seasonal Differenced Data\")\nplot4\n\nplot5 <- ggAcf(air_travel_ts %>% diff() %>% diff(12), lag.max = 30, main=\"Seasonal Differenced + First Differenced Data\")\nplot5\n```\n\n:::\n\nIn order to understand globalization in terms of South Korean culture globally, we'll also be looking at the number of inbound passengers into South Korea's Incheon airport from international flights. This data is monthly in nature, thus we'll clean the data in order to represent the date column as a datetime type in R. \n\nFirst, let's take a look at the **time series plot**. In comparison to HYBE and the globalization index, we can see that this data is seasonal, with peaks at approxiamtely the summer months of every year. This is of course due to travelers entering the country during the summer months on holiday. Additionally, we can also see a positive trend and cyclical patterns. One thing to point out is the dip in passengers during the summer of 2015. This is most likely due to the MERS outbreak in South Korea in May of 2015. This outbreak continued to that summer, and as a result, a siginifcantly fewer number of inbound tourists. \n\nThis plot depicts the **smoothing moving average** of our inbound passengers to South Korea. The smoothing windows I chose was 6 month, 12 month, and 36 months (or 3 years) on the monthly data. In all moving averages, we can confirm the existence of a smooth string positive upward trend in inbound passengers. Please note that because we are analyzing the nature of flights into country, we have removed the data from the year 2020 since the country of South Korea banned all incoming and outbound flights due to the COVID-19 global pandemic. \n\nNext, we'll take a look a monthly and yearly **lag plots** for inbound passengers. As we can see in both plots, there a strong positive correlation betwen months as well as between years in the data. This means that the data is most likely not stationary. To confirm this hypothesis, we'll analyze the **ACF and PACF** plots next. \n\nIn our ACF we see that there is a strong autocorrelation between all lags in the data as they are above the significance bands. While PACF for the most is not autocorrelated, we can say for now that differencing is nessesary. Using the **augmented dickey fuller test**, we can confirm our assumptions since we are rejecting the null hypothesis with 90% cofidence (0.09754 < 0.1). \n\nThus, in order to model this data, we will need to make it **stationary**. From the plotting output, we see that first difference and detrended data still produce a siginifcant amount of autocorrelation. Thus, after trying both seasonal differencing and seasonal + first differencing, we can we that seasonal + first differencing produces the best ACF plot and approximately stationary data. \n\n\n---\n\n## Popularity: KPOP \n\n::: {.panel-tabset}\n\n## Time Series Plot \n```{r}\n#| code-fold: true\nspotify <- read.csv(\"cleaned_data/spotify_data_cleaned.csv\")\n\n\n# Define KPOP and Western artists\nkpop_artists <- c(\"BLACKPINK\", \"BTS\", \"EXO\", \"Twice\")\nwestern_artists <- c(\"Harry Styles\", \"Beyoncé\", \"Drake\", \"Taylor Swift\")\n\nkpop_data <- spotify %>%\n  filter(artist_name %in% kpop_artists) %>%\n  group_by(album_release_year) %>%\n  summarise_at(vars(popularity), mean, na.rm = TRUE) %>%\n  mutate(artist_type = \"KPOP\") %>%\n  select(-artist_type) %>%\n  mutate(album_release_year = as.Date(as.character(album_release_year), format = \"%Y\"))\n\n# Separate data for Western artists\nwestern_data <- spotify %>%\n  filter(artist_name %in% western_artists) %>%\n  group_by(album_release_year) %>%\n  summarise_at(vars(popularity), mean, na.rm = TRUE) %>%\n  mutate(artist_type = \"Western\")%>%\n  select(-artist_type) %>%\n  mutate(album_release_year = as.Date(as.character(album_release_year), format = \"%Y\"))\n\nwrite_csv(kpop_data, \"cleaned_data/kpop_popularity.csv\")\nwrite_csv(western_data, \"cleaned_data/western_popularity.csv\")\n\n#Time series plot: \n\nkpop_ts <- ts(kpop_data$popularity, frequency = 1)\n\nautoplot(kpop_ts)+ggtitle(\"Average Popularity Score of KPOP Artists\") \n\n```\n\n## Moving Average Smoothing \n```{python}\n#| code-fold: true\n#| warning: false\n\n\nimport pandas as pd\nimport datetime\nimport plotly \nfrom datetime import datetime \nfrom pandas_datareader import data as pdr\nimport plotly.offline as pyo\nimport plotly.graph_objects as go \nfrom plotly.subplots import make_subplots\nimport plotly.express as px\n\nkpop_data = pd.read_csv('cleaned_data/kpop_popularity.csv')\nkpop_data['album_release_year'] = pd.to_datetime(kpop_data['album_release_year'])\n\nkpop_data['2yma'] = kpop_data['popularity'].rolling(window = 2).mean()\nkpop_data['3yma'] = kpop_data['popularity'].rolling(window = 3).mean()\nkpop_data['4yma'] = kpop_data['popularity'].rolling(window = 4).mean()\n\nfig = px.line(kpop_data, x='album_release_year', y=['popularity', '2yma', '3yma', '4yma'],\n              labels={'value': 'Yearly Data', 'variable': 'Moving Average'},\n              title='Yearly Data and Moving Averages for the Popularity Score of KPOP Artists')\n\n# Show the plot\nfig.show()\n\n```\n\n## Lag Plot\n```{r}\n#| code-fold: true\ngglagplot(kpop_ts, do.lines=FALSE)+\n  ggtitle(\"Lag Plot for Popularity Score of KPOP Artists\")+\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n```\n\n## ACF & PACF \n```{r}\n#| code-fold: true\nggAcf(kpop_ts, lag.max = 30)+ggtitle(\"ACF Plot for Popularity Score of KPOP Artists\")\nggPacf(kpop_ts, lag.max = 30)+ggtitle(\"PACF Plot for Popularity Score of KPOP Artists\")\n```\n\n## Dickie-Fuller Test\n```{r}\n#| code-fold: true\n#| warning: false\nkpop_test <- adf.test(kpop_ts)\nprint(kpop_test)\n```\n\n## Stationary\n```{r}\n#| code-fold: true\n#| warning: false\nfit = lm(kpop_ts~time(kpop_ts), na.action=NULL) \n\nplot1 <- ggAcf(kpop_ts, lag.max = 30, main=\"Original Data: Popularity Score of KPOP Artists\")\nplot2 <- ggAcf(resid(fit), lag.max = 30, main=\"Detrended data\") \nplot3 <- ggAcf(diff(kpop_ts), lag.max = 30, main=\"First Differenced Data\")\n\ngrid.arrange(plot1, plot2, plot3, ncol=3)\n```\n\n:::\n\n*As previously mentioned, the popularity score needed to be augmented due to Spotify's recent changes regarding their API, resulting in a smaller number of data points.*\n\nOur **times series plot** shows a steady, yet slightly positive trend in the data until 2023, where the popularity takes a sharp decline. This could be due to BTS, the most popular KPOP group, taking a hiatus this year due to their military enlistments. With that being said, we also cannot see any seasonality or cyclical trends. \n\nLooking at the **sma** plot, we can see that as we increase the yearly moving average to 4, we notice a downward trend to the data, clearly due to 2023. Similarly, the **lag plots** show that while their is some autocorrelation in the first 6 lags, this changes in the 9th lag, mainly due to the few lags available with our data. \n\nLooking at the **ACF & PACF** plots, we see that the data is well within the significance bounds, meaning that our data is stationary. Although the **Dickie-Fuller** test says otherwise, it is often inaccurate. Again, looking at the differenced and detrended data, we realize that the original data is stationary. \n\n## Popularity: Western \n\n::: {.panel-tabset}\n\n## Time Series Plot \n```{r}\n#| code-fold: true\n\n#Time series plot: \n\nwestern_ts <- ts(western_data$popularity, frequency = 1)\n\nautoplot(western_ts)+ggtitle(\"Average Popularity Score of Western Artists\") \n\n```\n\n## Moving Average Smoothing \n```{python}\n#| code-fold: true\n#| warning: false\n\n\nimport pandas as pd\nimport datetime\nimport plotly \nfrom datetime import datetime \nfrom pandas_datareader import data as pdr\nimport plotly.offline as pyo\nimport plotly.graph_objects as go \nfrom plotly.subplots import make_subplots\nimport plotly.express as px\n\nwestern_data = pd.read_csv('cleaned_data/western_popularity.csv')\nwestern_data['album_release_year'] = pd.to_datetime(western_data['album_release_year'])\n\nwestern_data['2yma'] = western_data['popularity'].rolling(window = 2).mean()\nwestern_data['3yma'] = western_data['popularity'].rolling(window = 3).mean()\nwestern_data['4yma'] = western_data['popularity'].rolling(window = 4).mean()\n\nfig = px.line(western_data, x='album_release_year', y=['popularity', '2yma', '3yma', '4yma'],\n              labels={'value': 'Yearly Data', 'variable': 'Moving Average'},\n              title='Yearly Data and Moving Averages for the Popularity Score of Western Artists')\n\n# Show the plot\nfig.show()\n\n```\n\n## Lag Plot\n```{r}\n#| code-fold: true\ngglagplot(western_ts, do.lines=FALSE)+\n  ggtitle(\"Lag Plot for Popularity Score of Western Artists\")+\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n```\n\n## ACF & PACF \n```{r}\n#| code-fold: true\nggAcf(western_ts, lag.max = 30)+ggtitle(\"ACF Plot for Popularity Score of Western Artists\")\nggPacf(western_ts, lag.max = 30)+ggtitle(\"PACF Plot for Popularity Score of Western Artists\")\n```\n\n## Dickie-Fuller Test\n```{r}\n#| code-fold: true\n#| warning: false\nkpop_test <- adf.test(western_ts)\nprint(kpop_test)\n```\n\n## Stationary\n```{r}\n#| code-fold: true\n#| warning: false\nfit = lm(western_ts~time(western_ts), na.action=NULL) \n\nplot1 <- ggAcf(western_ts, lag.max = 30, main=\"Original Data: Popularity Score of Western Artists\")\nplot2 <- ggAcf(resid(fit), lag.max = 30, main=\"Detrended data\") \nplot3 <- ggAcf(diff(western_ts), lag.max = 30, main=\"First Differenced Data\")\n\ngrid.arrange(plot1, plot2, plot3, ncol=3)\n```\n\n:::\n\n*As previously mentioned, the popularity score needed to be augmented due to Spotify's recent changes regarding their API, resulting in a smaller number of data points.*\n\nOur **times series plot** shows a steady positive trend in the data. Additionally, we can see some signs of seasonal patterns, however, given that the data is minimal, the strength of the seasonality is not strong enough to consider it. Lastly, we do not see any cyclical patterns either. \n\nLooking at the **sma** plot, we can see that as we increase the yearly moving average to 4, we notice an upward trend to the data with slight downtrending at the very end of the moving average. Similarly, the **lag plots** show that while their is some autocorrelation in all lags, but it is very weak. \n\nLooking at the **ACF & PACF** plots, we see that the data is well within the significance bounds, meaning that our data is stationary. Although the **Dickie-Fuller test** says otherwise, it is often inaccurate. Again, looking at the differenced and detrended data, we realize that the **original data is stationary**.\n\n","srcMarkdownNoYaml":"\n\nExploratory Data Analysis (EDA) for time series involves a systematic process to uncover patterns, trends, and underlying characteristics within the data. The initial step often includes a fundamental Time Series Plot, providing a visual representation of data points over time. Next, plotting the Simple Moving Average (SMA) aids in smoothing fluctuations and revealing long-term trends. Lag plots help identify localized patterns and autocorrelations within the time series, providing insights into potential cyclical behavior.\n\nThe examination of Autocorrelation Function (ACF) and Partial Autocorrelation Function (PACF) plots further refines our understanding of temporal dependencies and the need for differencing. This step is crucial in selecting appropriate parameters for time series models.\n\nIn addition to the ACF & PACF plots, the Dickey-Fuller Test is employed to identify stationarity. This statistical test evaluates whether a time series possesses a unit root, indicative of non-stationarity. A stationary time series exhibits consistent statistical properties over time, making it useful for modeling. \n\nThe purpose of EDA for our analysis is to confirm our univariate time series data is stationary prior to modeling. In our case, we will be performing EDA on the KOF globalization index, the record label of greatest interest, HYB Co., and the inbound passengers to South Korea. \n\n---\n\n```{r}\n#| code-fold: true\n#| code-summary: 'Importing Libraries'\n#| warning: false\n#| output: false\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(forecast)\nlibrary(astsa) \nlibrary(xts)\nlibrary(tseries)\nlibrary(fpp2)\nlibrary(fma)\nlibrary(lubridate)\nlibrary(tidyverse)\nlibrary(TSstudio)\nlibrary(quantmod)\nlibrary(tidyquant)\nlibrary(plotly)\nlibrary(ggplot2)\nlibrary(imputeTS)\nlibrary(gridExtra)\nlibrary(reticulate)\nlibrary(readxl)\nuse_python(\"/usr/local/bin/python3\", require = T)\nknitr::knit_engines$set(python = reticulate::eng_python)\npy_install(\"tensorflow\")\n```\n\n\n## Globalization\n\n::: {.panel-tabset}\n\n## Time Series plot\n```{r}\n#| warning: false\n#| code-fold: true\n\n# Import dataset\nglobal <- read_csv('cleaned_data/globalization.csv')\n\n# Filter information\nglobal <- global %>%\n  filter(country == 'United States') %>%\n  select(year, KOFGI) %>%\n  mutate(year = as.Date(year))\n\n# Create time series\nglobal_ts <-ts(global$KOFGI, star=decimal_date(as.Date(\"1970-01-01\", format = \"%Y-%m-%d\")), frequency = 1)\n\n# Create time series plot\nglobal_plot <- plot(as.ts(global_ts), main = \"Time Series of KOF Globalization Index within the United States\",\n                  xlab = 'Time', ylab = 'KOF Index')\n\n# Show plot\nggplotly(global_plot)\n\n```\n  \n\n## Moving Average Smoothing \n```{python}\n#| code-fold: true\n#| code-summary: 'SMA Code'\n#| warning: false\n\n\nimport pandas as pd\nimport datetime\nimport plotly \nfrom datetime import datetime \nfrom pandas_datareader import data as pdr\nimport plotly.offline as pyo\nimport plotly.graph_objects as go \nfrom plotly.subplots import make_subplots\nimport plotly.express as px\n\nglobal_data = pd.read_csv('cleaned_data/globalization.csv')\nglobal_data = global_data[global_data['country'] == 'United States']\nglobal_data['year'] = pd.to_datetime(global_data['year'], format='%Y')\n\nglobal_data['5yma'] = global_data['KOFGI'].rolling(window = 5).mean()\nglobal_data['10yma'] = global_data['KOFGI'].rolling(window = 10).mean()\nglobal_data['20yma'] = global_data['KOFGI'].rolling(window = 20).mean()\n\nfig = px.line(global_data, x='year', y=['KOFGI', '5yma', '10yma', '20yma'],\n              labels={'value': 'Yearly Data', 'variable': 'Moving Average'},\n              title='Yearly Data and Moving Averages for the Globalization Index')\n\n# Show the plot\nfig.show()\n```\n\n## Lag-plot \n```{r}\n#| warning: false\n#| code-fold: true\ngglagplot(global_ts, do.lines=FALSE)+ggtitle(\"Lag Plot for the KOF Globalization Index\")\n```\n\n## ACF & PACF \n```{r}\n#| warning: false\n#| code-fold: true\nggAcf(global_ts)+ggtitle(\"ACF Plot for Globalization Index\")\nggPacf(global_ts)+ggtitle(\"PACF Plot for Globalization Index\")\n```\n\n## Dickey-Fuller Test\n```{r}\n#| warning: false\n#| code-fold: true\nglobal_test <- adf.test(global_ts)\nprint(global_test)\n```\n\n## Stationary \n```{r}\n#| warning: false\n#| code-fold: true\nfit = lm(global_ts~time(global_ts), na.action=NULL) \n\nplot1 <- ggAcf(global_ts, 50, main=\"Original Data: Globalization Index\")\nplot2 <- ggAcf(resid(fit), 50, main=\"Detrended data\") \nplot3 <- ggAcf(diff(global_ts), 50, main=\"First Differenced Data\")\n\ngrid.arrange(plot1, plot2, plot3,ncol=3)\n```\n\n:::\n\nLet's begin by anaylzing globalization of the United States from 1970 to 2022. I will be using the general globalization index for this time series anaylsis. First I will begin by filtering the data and creating a time series object in R. This will allow us to **plot the time series** data for initial analysis.\n\nFrom the plot of the globalization index in the United States, we can see a strong positive upward trend. In terms of seasonality and cyclic patterns, we are unable to see such patterns in the data. Additionally, we can see very slight peaks in the data in 1986 and 2009, however, they are not enough to conclude any patterns of interest. Thus,we can say this plot is neither additive nor multiplicative. \n\nNext, we'll take a look at a **moving average smoothing** plot to obtain some information on potential crossings. \n\nThe plot shows us the smoothing moving average for the yearly KOF globalization index data. The three types of smoothing I chose was 5-year, 10-year, and 20-year moving averages. As we can see in the graph, all smoothing lines show a positive upward trend across the time interval (the past 50 years). There is also no crossing between the smoothing lines, possibly indicating that the data had a constant upward trend with no seasonality or cyclical trends throughout. \n\nNext, let's take a look at a few **lag plots** of data on itself as well ACF and PACF in order to identify possible signs of stationarity. \n\nWe can see in lags 1,2, and 3 a very strong positive linear relationship, meaning a positive autocorrelation in the lags. From lag 4 and onward, the trend is still strongly positive, but less linear, suggesting a weaker autocorrelation. We also don't see any groupings in the lags, suggesting that there is no seasonality in the data. \n\nLooking at the **ACF and PACF** plots, we get a better understanding this time series. The ACF plot shows the present lag is significantly correlated with the first 12 years, after which it become significantly uncorrelated. Additionally, the PACF shows a stationary plot, due to the PACF values being contained in the significance bands. Thus, we can say that there is in fact strong autocorrelation in this time series data, however correlation is not present within the residuals. \n\nThe **Dickey-Fuller Test**, which tests the alternative hypothesis that the time series is stationary, returned a p-value of 0.99. Since 0.99 > 0.05, we do not have enough evidence and thus, fail to reject the null hypothesis, meaning that the time series object is not stationary. However, since we got different results from the ACF and PACF, we'll proceed with the ACF results and difference/detrend the data.  \n\nTherefore, in order to obtain stationary data to runs an ARMA and AMRIMA model on, we will need to compare **differenced and detrended** data to find which approach produces stationary data. \n\nFrom this plot, we can clearly see that the first differenced data results in a stationary plot, with the ACF values inside the significance bands. Since the first difference was able to coerce the data to be stationary, we can also say that the original data was linearly trended. Thus, moving forward, we will use first differencing on the globalization index in order to model this value. \n\n---\n\n## Stock Prices: Looking at HYBE Entertainment\n\n::: {.panel-tabset}\n\n## Time Series plot \n```{r}\n#| warning: false\n#| code-fold: true\noptions(\"getSymbols.warning4.0\"=FALSE)\noptions(\"getSymbols.yahoo.warning\"=FALSE)\n\n\nname <- getSymbols('352820.KS', from = \"2019-01-01\", to = \"2023-09-01\")\nHYBE <- data.frame(`352820.KS`$`352820.KS.Adjusted`)\nHYBE <- HYBE %>%\n  rownames_to_column(var = \"Date\") %>%\n  mutate(Date = as.Date(Date)) %>%\n  rename(Price = X352820.KS.Adjusted) %>%\n  mutate(Price = Price/1352.60)\n\nstart_date <- as.Date(\"2020-10-15\")\nend_date <- as.Date(\"2023-09-01\")\n\nall_dates <- data.frame(Date = seq(start_date, end_date, by = \"days\"))\n\nmerged_data <- all_dates %>%\n  left_join(HYBE, by = \"Date\")\n\nimputed_time_series <- na_ma(merged_data, k = 4, weighting = \"exponential\")\ndf_HYBE <-data.frame(imputed_time_series)\ndf_HYBE$Date <-as.Date(df_HYBE$Date,format = \"%Y-%m-%d\")\n\nwrite.csv(df_HYBE, 'cleaned_data/HYBE_cleaned_data.csv')\n\n# Create time series\nHYBE_ts <-ts(df_HYBE$Price, star=decimal_date(as.Date(\"2020-10-15\", format = \"%Y-%m-%d\")), frequency = 365.25)\n\n# Create time series plot\nHYBE_plot <- plot(as.ts(HYBE_ts), main = \"Time Series of HYBE Stock Prices\",\n                  xlab = 'Time', ylab = 'Price (USD)')\n```\n\n## Moving Average Smoothing \n```{python}\n#| code-fold: true\n#| code-summary: 'SMA Code'\n#| warning: false\nHYBE_data = pd.read_csv('cleaned_data/HYBE_cleaned_data.csv')\n\nHYBE_data.drop(HYBE_data.columns[0], axis=1, inplace = True)\nHYBE_data['Date'] = pd.to_datetime(HYBE_data['Date'])\nHYBE_data.dropna(axis  = 0, inplace = True)\n\nHYBE_data['3wma'] = HYBE_data['Price'].rolling(window = 15).mean()\nHYBE_data['20wma'] = HYBE_data['Price'].rolling(window = 100).mean()\nHYBE_data['50wma'] = HYBE_data['Price'].rolling(window = 250).mean()\n\nfig = px.line(HYBE_data, x='Date', y=['Price', '3wma', '20wma', '50wma'],\n              labels={'value': 'Daily Data', 'variable': 'Weekly Moving Average'},\n              title='Smoothing Moving Averages for HYBE Stock')\n\n# Show the plot\nfig.show()\n```\n\n## Lag-plot\n```{r}\n#| warning: false\n#| code-fold: true\ngglagplot(HYBE_ts, do.lines=FALSE)+\n  ggtitle(\"Lag Plot for HYBE Stock Prices\")+\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n```\n\n## ACF & PACF\n```{r}\n#| warning: false\n#| code-fold: true\nggAcf(HYBE_ts, lag.max = 30)+ggtitle(\"ACF Plot for HYBE Stock Prices\")\nggPacf(HYBE_ts, lag.max = 30)+ggtitle(\"PACF Plot for HYBE Stock Prices\")\n```\n\n## Dickey-Fuller Test\n```{r}\n#| warning: false\n#| code-fold: true\nHYBE_test <- adf.test(HYBE_ts)\nprint(HYBE_test)\n```\n\n## Stationary\n```{r}\n#| warning: false\n#| code-fold: true\nfit = lm(HYBE_ts~time(HYBE_ts), na.action=NULL) \n\nplot1 <- ggAcf(HYBE_ts, lag.max = 30, main=\"Original Data: HYBE Stock Prices\")\nplot2 <- ggAcf(resid(fit), lag.max = 30, main=\"Detrended data\") \nplot3 <- ggAcf(diff(HYBE_ts), lag.max = 30, main=\"First Differenced Data\")\n\ngrid.arrange(plot1, plot2, plot3, ncol=3)\n```\n\n```{r}\n#| warning: false\n#| code-fold: true\nplot4 <- ggAcf(diff(diff(HYBE_ts)), lag.max = 30, main=\"Second Differenced Data\")\nplot4\n```\n\n::: \n\nNext, since we saw, through the initial data visualization, the prevelance of KPOP, and specifically BTS, on the western music industry, we will take a look at HYBE stock prices through further time series EDA. \n\nPrimarily, we will clean our data such that missing dates corresponding to weekends and holidays where the stock market is closed will be estimated through exponential prediction. After which we will take the data and transform it into a **time series object to plot**.\n\nUnlike the globalization index, the HYBE stock price fluctuates quite frequently in the smaller range of time. From 2021 to 2022, we can see a strong positive trend with slight seasonality. However, from 2022 onwards we see a sharp downward trend and with varying degrees of peaks. Thus, the uneven nature of the peaks and troughs results in data that is neither additive or multiplicative. Additionally, since the dataset is smaller, we cannot say anything of certain regarding cyclical patterns. \n\nNow, let's look at the **SMA graph** for HYBE stock to identify potential crossings. \n\nThis plot depicts the smoothing moving average of HYBE stock prices. The smoothing windows I chose was 3-week, 20-week, and 50-week on the daily data. As we can see, the 3-week smoothing line is closely correlated with the actual prices, as expected. We can also see some crossings between the 3 smoothing moving averages. Primarily, we can see a crossing in September of 2021, where the 3-week SMA briefly crosses under and over the 20-week line. The crossing over of a shorter SMA, also called a golden cross, indicates that a postive trend in prices was to be expected, which is what occured. This is most likely due to the announcement of BTS performing at the 2021 Grammy Music Awards. Additionally, we can see a significant crossing again in April of 2022. This is when the 3-week and 20-week line cross under the 50-week. When a shorter term SMA cross under the longer SMA, we can infer a drop in stock prices, also called a Death Cross. This inevitably did happen, most likely due to talk of BTS's enlistment into the Korean military as a part of mandatory service, which was officially announced June of that year. \n\nNext, let's take a look at a few **lag plots** of data on itself as well ACF and PACF in order to identify possible signs of stationarity. \n\nThese lag plots show similar results to that of the globalization index. The forst four lags have a very strong positive linear correlation, suggesting autocorrelation amongst those lags. From lag 5 onwards, we still see a string linear correlation, however we can also see a small circular pattern forming in the lag plots, suggesting a possibility of single-cycle sinusodial data. \n\nLooking at the **ACF & PACF** plots, the ACF plot shows the present lag is significantly correlated with all other present lags in the plot, since all values are well above the siginificance bands. Additionally, the PACF shows a stationary plot, due to the PACF values being contained in the significance bands. Thus, we can say that there is in fact strong autocorrelation in this time series data, however correlation is not present within the residuals. \n\nThe **Dickey-Fuller Test** resulted in a p-value of 0.5737. Since 0.5737 > 0.05, we can fail to reject the null hypothesis and say that the time series object is not stationary. However, since we got different results from the ACF and PACF, we'll proceed with the ACF results and difference/detrend the data. \n\nHowever, after trying both **detrending and first difference** methods, both result in ACF plots showing autocorrelation and non-stationary tendencies. Thus, we will try the second differencing approach. \n\nWith the second difference, we were able to get the HYBE stock prices to become stationary. Therefore, we could also suggest the original data has quadratic trending behavior. \n\nThus, going forward, we can use the second difference of the HYBE stock prices for modeling.\n\n---\n\n## Korean Tourism\n\n::: {.panel-tabset}\n\n## Time Series Plot\n```{r}\n#| warning: false\n#| code-fold: true\nsk_passengers <- read_xlsx('raw_data/sk_passenger_arrivals.xlsx')\n\nsk_passengers <- sk_passengers %>%\n  unite(date, year, month, sep = '-') %>%\n  mutate(date = as.Date(paste(date, '01', sep = '-'))) %>%\n  filter(year(date) < 2020) #In order to avoid the anomaly of the 2020 pandemic\n\nwrite.csv(sk_passengers, \"cleaned_data/air_passengers_cleaned.csv\")\n\nair_travel_ts <- ts(sk_passengers$Passengers, start = c(2010, 10), \n                    frequency = 12)\n\nautoplot(air_travel_ts)+ggtitle(\"Air passenger arrivals to Incheon Airport (SK)\") \n```\n\n## Moving Average Smoothing \n```{python}\n#| code-fold: true\n#| code-summary: 'SMA Code'\n#| warning: false\n\nimport pandas as pd\nimport datetime\nimport plotly \nfrom datetime import datetime \nfrom pandas_datareader import data as pdr\nimport plotly.offline as pyo\nimport plotly.graph_objects as go \nfrom plotly.subplots import make_subplots\nimport plotly.express as px\n\nglobal_data = pd.read_csv('cleaned_data/air_passengers_cleaned.csv')\nglobal_data['date'] = pd.to_datetime(global_data['date'], format='%Y-%m')\n\nglobal_data['6mma'] = global_data['Passengers'].rolling(window = 6).mean()\nglobal_data['12mma'] = global_data['Passengers'].rolling(window = 12).mean()\nglobal_data['36mma'] = global_data['Passengers'].rolling(window = 36).mean()\n\nfig = px.line(global_data, x='date', y=['Passengers', '6mma', '12mma', '36mma'],\n              labels={'value': 'Monthly Data', 'variable': 'Moving Average'},\n              title='Monthly Data and Moving Averages for the Inbound Passengers to SK')\n\n# Show the plot\nfig.show()\n```\n\n## Lag-plot\n```{r}\n#| warning: false\n#| code-fold: true\ngglagplot(air_travel_ts, do.lines=FALSE)+\n  ggtitle(\"Lag Plot for Inbound Passengers to SK\")+\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n\ngglagplot(air_travel_ts, do.lines=FALSE, set.lags = c(12, 24, 36, 48))+\n  ggtitle(\"Air passenger arrivals to Incheon Airport (SK)\") \n```\n\n## ACF & PACF\n```{r}\n#| warning: false\n#| code-fold: true\nggAcf(air_travel_ts, lag.max = 30)+ggtitle(\"ACF Plot for Inbound Passengers to SK\")\nggPacf(air_travel_ts, lag.max = 30)+ggtitle(\"PACF Plot for Inbound Passengers to SK\")\n```\n\n## Dickey-Fuller Test\n```{r}\n#| warning: false\n#| code-fold: true\npassengers_test <- adf.test(air_travel_ts)\nprint(passengers_test)\n```\n\n## Stationary\n```{r}\n#| warning: false\n#| code-fold: true\nfit = lm(air_travel_ts~time(air_travel_ts), na.action=NULL) \n\nplot1 <- ggAcf(air_travel_ts, lag.max = 30, main=\"Original Data: Inbound Passengers to SK\")\nplot2 <- ggAcf(resid(fit), lag.max = 30, main=\"Detrended data\") \nplot3 <- ggAcf(diff(air_travel_ts), lag.max = 30, main=\"First Differenced Data\")\n\ngrid.arrange(plot1, plot2, plot3, ncol=3)\n```\n\n```{r}\n#| warning: false\n#| code-fold: true\nplot4 <- ggAcf(air_travel_ts %>% diff(12), lag.max = 30, main=\"Seasonal Differenced Data\")\nplot4\n\nplot5 <- ggAcf(air_travel_ts %>% diff() %>% diff(12), lag.max = 30, main=\"Seasonal Differenced + First Differenced Data\")\nplot5\n```\n\n:::\n\nIn order to understand globalization in terms of South Korean culture globally, we'll also be looking at the number of inbound passengers into South Korea's Incheon airport from international flights. This data is monthly in nature, thus we'll clean the data in order to represent the date column as a datetime type in R. \n\nFirst, let's take a look at the **time series plot**. In comparison to HYBE and the globalization index, we can see that this data is seasonal, with peaks at approxiamtely the summer months of every year. This is of course due to travelers entering the country during the summer months on holiday. Additionally, we can also see a positive trend and cyclical patterns. One thing to point out is the dip in passengers during the summer of 2015. This is most likely due to the MERS outbreak in South Korea in May of 2015. This outbreak continued to that summer, and as a result, a siginifcantly fewer number of inbound tourists. \n\nThis plot depicts the **smoothing moving average** of our inbound passengers to South Korea. The smoothing windows I chose was 6 month, 12 month, and 36 months (or 3 years) on the monthly data. In all moving averages, we can confirm the existence of a smooth string positive upward trend in inbound passengers. Please note that because we are analyzing the nature of flights into country, we have removed the data from the year 2020 since the country of South Korea banned all incoming and outbound flights due to the COVID-19 global pandemic. \n\nNext, we'll take a look a monthly and yearly **lag plots** for inbound passengers. As we can see in both plots, there a strong positive correlation betwen months as well as between years in the data. This means that the data is most likely not stationary. To confirm this hypothesis, we'll analyze the **ACF and PACF** plots next. \n\nIn our ACF we see that there is a strong autocorrelation between all lags in the data as they are above the significance bands. While PACF for the most is not autocorrelated, we can say for now that differencing is nessesary. Using the **augmented dickey fuller test**, we can confirm our assumptions since we are rejecting the null hypothesis with 90% cofidence (0.09754 < 0.1). \n\nThus, in order to model this data, we will need to make it **stationary**. From the plotting output, we see that first difference and detrended data still produce a siginifcant amount of autocorrelation. Thus, after trying both seasonal differencing and seasonal + first differencing, we can we that seasonal + first differencing produces the best ACF plot and approximately stationary data. \n\n\n---\n\n## Popularity: KPOP \n\n::: {.panel-tabset}\n\n## Time Series Plot \n```{r}\n#| code-fold: true\nspotify <- read.csv(\"cleaned_data/spotify_data_cleaned.csv\")\n\n\n# Define KPOP and Western artists\nkpop_artists <- c(\"BLACKPINK\", \"BTS\", \"EXO\", \"Twice\")\nwestern_artists <- c(\"Harry Styles\", \"Beyoncé\", \"Drake\", \"Taylor Swift\")\n\nkpop_data <- spotify %>%\n  filter(artist_name %in% kpop_artists) %>%\n  group_by(album_release_year) %>%\n  summarise_at(vars(popularity), mean, na.rm = TRUE) %>%\n  mutate(artist_type = \"KPOP\") %>%\n  select(-artist_type) %>%\n  mutate(album_release_year = as.Date(as.character(album_release_year), format = \"%Y\"))\n\n# Separate data for Western artists\nwestern_data <- spotify %>%\n  filter(artist_name %in% western_artists) %>%\n  group_by(album_release_year) %>%\n  summarise_at(vars(popularity), mean, na.rm = TRUE) %>%\n  mutate(artist_type = \"Western\")%>%\n  select(-artist_type) %>%\n  mutate(album_release_year = as.Date(as.character(album_release_year), format = \"%Y\"))\n\nwrite_csv(kpop_data, \"cleaned_data/kpop_popularity.csv\")\nwrite_csv(western_data, \"cleaned_data/western_popularity.csv\")\n\n#Time series plot: \n\nkpop_ts <- ts(kpop_data$popularity, frequency = 1)\n\nautoplot(kpop_ts)+ggtitle(\"Average Popularity Score of KPOP Artists\") \n\n```\n\n## Moving Average Smoothing \n```{python}\n#| code-fold: true\n#| warning: false\n\n\nimport pandas as pd\nimport datetime\nimport plotly \nfrom datetime import datetime \nfrom pandas_datareader import data as pdr\nimport plotly.offline as pyo\nimport plotly.graph_objects as go \nfrom plotly.subplots import make_subplots\nimport plotly.express as px\n\nkpop_data = pd.read_csv('cleaned_data/kpop_popularity.csv')\nkpop_data['album_release_year'] = pd.to_datetime(kpop_data['album_release_year'])\n\nkpop_data['2yma'] = kpop_data['popularity'].rolling(window = 2).mean()\nkpop_data['3yma'] = kpop_data['popularity'].rolling(window = 3).mean()\nkpop_data['4yma'] = kpop_data['popularity'].rolling(window = 4).mean()\n\nfig = px.line(kpop_data, x='album_release_year', y=['popularity', '2yma', '3yma', '4yma'],\n              labels={'value': 'Yearly Data', 'variable': 'Moving Average'},\n              title='Yearly Data and Moving Averages for the Popularity Score of KPOP Artists')\n\n# Show the plot\nfig.show()\n\n```\n\n## Lag Plot\n```{r}\n#| code-fold: true\ngglagplot(kpop_ts, do.lines=FALSE)+\n  ggtitle(\"Lag Plot for Popularity Score of KPOP Artists\")+\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n```\n\n## ACF & PACF \n```{r}\n#| code-fold: true\nggAcf(kpop_ts, lag.max = 30)+ggtitle(\"ACF Plot for Popularity Score of KPOP Artists\")\nggPacf(kpop_ts, lag.max = 30)+ggtitle(\"PACF Plot for Popularity Score of KPOP Artists\")\n```\n\n## Dickie-Fuller Test\n```{r}\n#| code-fold: true\n#| warning: false\nkpop_test <- adf.test(kpop_ts)\nprint(kpop_test)\n```\n\n## Stationary\n```{r}\n#| code-fold: true\n#| warning: false\nfit = lm(kpop_ts~time(kpop_ts), na.action=NULL) \n\nplot1 <- ggAcf(kpop_ts, lag.max = 30, main=\"Original Data: Popularity Score of KPOP Artists\")\nplot2 <- ggAcf(resid(fit), lag.max = 30, main=\"Detrended data\") \nplot3 <- ggAcf(diff(kpop_ts), lag.max = 30, main=\"First Differenced Data\")\n\ngrid.arrange(plot1, plot2, plot3, ncol=3)\n```\n\n:::\n\n*As previously mentioned, the popularity score needed to be augmented due to Spotify's recent changes regarding their API, resulting in a smaller number of data points.*\n\nOur **times series plot** shows a steady, yet slightly positive trend in the data until 2023, where the popularity takes a sharp decline. This could be due to BTS, the most popular KPOP group, taking a hiatus this year due to their military enlistments. With that being said, we also cannot see any seasonality or cyclical trends. \n\nLooking at the **sma** plot, we can see that as we increase the yearly moving average to 4, we notice a downward trend to the data, clearly due to 2023. Similarly, the **lag plots** show that while their is some autocorrelation in the first 6 lags, this changes in the 9th lag, mainly due to the few lags available with our data. \n\nLooking at the **ACF & PACF** plots, we see that the data is well within the significance bounds, meaning that our data is stationary. Although the **Dickie-Fuller** test says otherwise, it is often inaccurate. Again, looking at the differenced and detrended data, we realize that the original data is stationary. \n\n## Popularity: Western \n\n::: {.panel-tabset}\n\n## Time Series Plot \n```{r}\n#| code-fold: true\n\n#Time series plot: \n\nwestern_ts <- ts(western_data$popularity, frequency = 1)\n\nautoplot(western_ts)+ggtitle(\"Average Popularity Score of Western Artists\") \n\n```\n\n## Moving Average Smoothing \n```{python}\n#| code-fold: true\n#| warning: false\n\n\nimport pandas as pd\nimport datetime\nimport plotly \nfrom datetime import datetime \nfrom pandas_datareader import data as pdr\nimport plotly.offline as pyo\nimport plotly.graph_objects as go \nfrom plotly.subplots import make_subplots\nimport plotly.express as px\n\nwestern_data = pd.read_csv('cleaned_data/western_popularity.csv')\nwestern_data['album_release_year'] = pd.to_datetime(western_data['album_release_year'])\n\nwestern_data['2yma'] = western_data['popularity'].rolling(window = 2).mean()\nwestern_data['3yma'] = western_data['popularity'].rolling(window = 3).mean()\nwestern_data['4yma'] = western_data['popularity'].rolling(window = 4).mean()\n\nfig = px.line(western_data, x='album_release_year', y=['popularity', '2yma', '3yma', '4yma'],\n              labels={'value': 'Yearly Data', 'variable': 'Moving Average'},\n              title='Yearly Data and Moving Averages for the Popularity Score of Western Artists')\n\n# Show the plot\nfig.show()\n\n```\n\n## Lag Plot\n```{r}\n#| code-fold: true\ngglagplot(western_ts, do.lines=FALSE)+\n  ggtitle(\"Lag Plot for Popularity Score of Western Artists\")+\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n```\n\n## ACF & PACF \n```{r}\n#| code-fold: true\nggAcf(western_ts, lag.max = 30)+ggtitle(\"ACF Plot for Popularity Score of Western Artists\")\nggPacf(western_ts, lag.max = 30)+ggtitle(\"PACF Plot for Popularity Score of Western Artists\")\n```\n\n## Dickie-Fuller Test\n```{r}\n#| code-fold: true\n#| warning: false\nkpop_test <- adf.test(western_ts)\nprint(kpop_test)\n```\n\n## Stationary\n```{r}\n#| code-fold: true\n#| warning: false\nfit = lm(western_ts~time(western_ts), na.action=NULL) \n\nplot1 <- ggAcf(western_ts, lag.max = 30, main=\"Original Data: Popularity Score of Western Artists\")\nplot2 <- ggAcf(resid(fit), lag.max = 30, main=\"Detrended data\") \nplot3 <- ggAcf(diff(western_ts), lag.max = 30, main=\"First Differenced Data\")\n\ngrid.arrange(plot1, plot2, plot3, ncol=3)\n```\n\n:::\n\n*As previously mentioned, the popularity score needed to be augmented due to Spotify's recent changes regarding their API, resulting in a smaller number of data points.*\n\nOur **times series plot** shows a steady positive trend in the data. Additionally, we can see some signs of seasonal patterns, however, given that the data is minimal, the strength of the seasonality is not strong enough to consider it. Lastly, we do not see any cyclical patterns either. \n\nLooking at the **sma** plot, we can see that as we increase the yearly moving average to 4, we notice an upward trend to the data with slight downtrending at the very end of the moving average. Similarly, the **lag plots** show that while their is some autocorrelation in all lags, but it is very weak. \n\nLooking at the **ACF & PACF** plots, we see that the data is well within the significance bounds, meaning that our data is stationary. Although the **Dickie-Fuller test** says otherwise, it is often inaccurate. Again, looking at the differenced and detrended data, we realize that the **original data is stationary**.\n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["styles.css"],"toc":true,"output-file":"eda.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.450","theme":"minty","title":"Exploratory Data Analysis"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}