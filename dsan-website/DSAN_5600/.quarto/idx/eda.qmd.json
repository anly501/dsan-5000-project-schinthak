{"title":"Exploratory Data Analysis","markdown":{"yaml":{"title":"Exploratory Data Analysis"},"headingText":"Globalization:","containsRefs":false,"markdown":"\n\nNow, I will be conducting a Time Series EDA analysis on the globalization indexes and the record label stock prices. Due to the structure of the other data, I cannot conduct further time series EDA on those sets. \n\n```{r}\n#| code-fold: true\n#| code-summary: 'Importing Libraries'\n#| warning: false\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(forecast)\nlibrary(astsa) \nlibrary(xts)\nlibrary(tseries)\nlibrary(fpp2)\nlibrary(fma)\nlibrary(lubridate)\nlibrary(tidyverse)\nlibrary(TSstudio)\nlibrary(quantmod)\nlibrary(tidyquant)\nlibrary(plotly)\nlibrary(ggplot2)\nlibrary(imputeTS)\nlibrary(gridExtra)\nlibrary(reticulate)\nuse_python(\"/usr/local/bin/python3\", require = T)\nknitr::knit_engines$set(python = reticulate::eng_python)\n```\n\n\nLet's begin by anaylzing globalization of the United States from 1970 to 2022. I will be using the general globalization index for this time series anaylsis. First I will begin by filtering the data and creating a time series object in R. This will allow us to plot the time series data for initial analysis. \n\n### Time Series plot: \n```{r}\n#| warning: false\n#| code-fold: true\n\n# Import dataset\nglobal <- read_csv('globalization.csv')\n\n# Filter information\nglobal <- global %>%\n  filter(country == 'United States') %>%\n  select(year, KOFGI) %>%\n  mutate(year = as.Date(year))\n\n# Create time series\nglobal_ts <-ts(global$KOFGI, star=decimal_date(as.Date(\"1970-01-01\", format = \"%Y-%m-%d\")), frequency = 1)\n\n# Create time series plot\nglobal_plot <- plot(as.ts(global_ts), main = \"Time Series of KOF Globalization Index within the United States\",\n                  xlab = 'Time', ylab = 'KOF Index')\n\n# Show plot\nggplotly(global_plot)\n\n```\n\nFrom the plot of the globalization index in the United States, we can see a strong positive upward trend. In terms of seasonality and cyclic patterns, we are unable to see such patterns in the plot. Additionally, we can see very slight peaks in the data in 1986 and 2009, however, they are not enough to conclude any patterns in the data. Thus,we can say this plot is neither additive nor multiplicative. \n\nNext, we'll take a look at a moving average smoothing plot to obtain some information on potential crossings.  \n\n### Moving Average Smoothing: \n```{python}\n#| code-fold: true\n#| code-summary: 'SMA Code'\n#| warning: false\n\n\nimport pandas as pd\nimport datetime\nimport plotly \nfrom datetime import datetime \nfrom pandas_datareader import data as pdr\nimport plotly.offline as pyo\nimport plotly.graph_objects as go \nfrom plotly.subplots import make_subplots\nimport plotly.express as px\n\nglobal_data = pd.read_csv('globalization.csv')\nglobal_data = global_data[global_data['country'] == 'United States']\nglobal_data['year'] = pd.to_datetime(global_data['year'], format='%Y')\n\nglobal_data['5yma'] = global_data['KOFGI'].rolling(window = 5).mean()\nglobal_data['10yma'] = global_data['KOFGI'].rolling(window = 10).mean()\nglobal_data['20yma'] = global_data['KOFGI'].rolling(window = 20).mean()\n\nfig = px.line(global_data, x='year', y=['KOFGI', '5yma', '10yma', '20yma'],\n              labels={'value': 'Yearly Data', 'variable': 'Moving Average'},\n              title='Yearly Data and Moving Averages for the Globalization Index')\n\n# Show the plot\nfig.show()\n```\n\nThis plot shows us the smoothing moving average for the yearly KOF globalization index data. The three types of smoothing I chose was 5-year, 10-year, and 20-year moving averages. As we can see in the graph, all smoothing lines show a positive upward trend across the time interval (the past 50 years). There is also no crossing between the smoothing lines, possibly indicating that the data had a constant upward trend with no seasonality or cyclical trends throughout. \n\nNext, let's take a look at a few lag plots of data on itself as well ACF and PACF in order to identify possible signs of stationarity. \n\n### Lag-plot: \n```{r}\n#| warning: false\n#| code-fold: true\ngglagplot(global_ts, do.lines=FALSE)+ggtitle(\"Lag Plot for the KOF Globalization Index\")\n```\n\nWe can see in lags 1,2, and 3 a very strong positive linear relationship, meaning a positive autocorrelation in the lags. From lag 4 and onward, the trend is still strongly positive, but less linear, suggesting a weaker autocorrelation. We also don't see any groupings in the lags, suggesting that there is no seasonality in the data. \n\n### ACF & PACF: \n```{r}\n#| warning: false\n#| code-fold: true\nggAcf(global_ts)+ggtitle(\"ACF Plot for Globalization Index\")\nggPacf(global_ts)+ggtitle(\"PACF Plot for Globalization Index\")\n```\n\nLooking at the ACF and PACF plots, we get a better understanding this time series. The ACF plot shows the present lag is significantly correlated with the first 12 years, after which it become significantly uncorrelated. Additionally, the PACF shows a stationary plot, due to the PACF values being contained in the significance bands. Thus, we can say that there is in fact strong autocorrelation in this time series data, however correlation is not present within the residuals. \n\n### Dickey-Fuller Test\n```{r}\n#| warning: false\n#| code-fold: true\nglobal_test <- adf.test(global_ts)\nprint(global_test)\n```\n\nThe Dickey-Fuller Test, with tests the alternative hypothesis that the time series is stationary, concluded a p-value of 0.99. Since 0.99 > 0.05, we do not have enough evidence and thus, fail to rejec the null hypothesis, meaning that the time series object is not stationary. \n\n### Stationary: \nTherefore, in order to obtain stationary data to runs an ARMA and AMRIMA model on, we will need to compare differenced and detrended data to find which approach produces stationary data. \n\n```{r}\n#| warning: false\n#| code-fold: true\nfit = lm(global_ts~time(global_ts), na.action=NULL) \n\nplot1 <- ggAcf(global_ts, 50, main=\"Original Data: Globalization Index\")\nplot2 <- ggAcf(resid(fit), 50, main=\"Detrended data\") \nplot3 <- ggAcf(diff(global_ts), 50, main=\"First Differenced Data\")\n\ngrid.arrange(plot1, plot2, plot3,ncol=3)\n```\n\nFrom this plot, we can clearly see that the first differenced data results in a stationary plot, with the ACF values inside the significance bands. Since the first difference was able to coerce the data to be stationary, we can also say that the original data was linearly trended. Thus, moving forward, we will use first differencing on the globalization index in order to model this value. \n\n## Stock Prices: Looking at HYBE Entertainment\n### Time Series plot:\n\nNext, since we saw, through the initial data visualization, the prevelance of Kpop and specifically BTS on the western music industry, we will take a look at HYBE stock prices through further time series EDA. \n\nPrimarily, we will clean our data such that missing dates corresponding to weekends and holidays where the stock market is closed will be estimated through exponential prediction. After which we will take the data and transform it into a time series object to plot. \n\n```{r}\n#| warning: false\n#| code-fold: true\noptions(\"getSymbols.warning4.0\"=FALSE)\noptions(\"getSymbols.yahoo.warning\"=FALSE)\n\n\nname <- getSymbols('352820.KS', from = \"2019-01-01\", to = \"2023-09-01\")\nHYBE <- data.frame(`352820.KS`$`352820.KS.Adjusted`)\nHYBE <- HYBE %>%\n  rownames_to_column(var = \"Date\") %>%\n  mutate(Date = as.Date(Date)) %>%\n  rename(Price = X352820.KS.Adjusted) %>%\n  mutate(Price = Price/1352.60)\n\nstart_date <- as.Date(\"2020-10-15\")\nend_date <- as.Date(\"2023-09-01\")\n\nall_dates <- data.frame(Date = seq(start_date, end_date, by = \"days\"))\n\nmerged_data <- all_dates %>%\n  left_join(HYBE, by = \"Date\")\n\nwrite.csv(merged_data, 'HYBE_cleaned_data.csv')\n\nimputed_time_series <- na_ma(merged_data, k = 4, weighting = \"exponential\")\ndf_HYBE <-data.frame(imputed_time_series)\ndf_HYBE$Date <-as.Date(df_HYBE$Date,format = \"%Y-%m-%d\")\n\n# Create time series\nHYBE_ts <-ts(df_HYBE$Price, star=decimal_date(as.Date(\"2020-10-15\", format = \"%Y-%m-%d\")), frequency = 365.25)\n\n# Create time series plot\nHYBE_plot <- plot(as.ts(HYBE_ts), main = \"Time Series of HYBE Stock Prices\",\n                  xlab = 'Time', ylab = 'Price (USD)')\n```\n\nUnlike the globalization index, the HYBE stock price fluctuates quite frequently in the smaller range of time. From 2021 to 2022, we can see a strong positive trend with slight seasonality. However, from 2022 onwards we see a sharp downward trend and with varying degrees of peaks. Thus, the uneven nature of the peaks and troughs results in data that is neither additive or multiplicative. Additionally, since the dataset is smaller, we cannot say anything of certain regarding cyclical patterns. \n\nNow, let's look at the SMA graph for HYBE stock to identify potential crossings. \n\n### Moving Average Smoothing: \n```{python}\n#| code-fold: true\n#| code-summary: 'SMA Code'\n#| warning: false\nHYBE_data = pd.read_csv('HYBE_cleaned_data.csv')\n\nHYBE_data.drop(HYBE_data.columns[0], axis=1, inplace = True)\nHYBE_data['Date'] = pd.to_datetime(HYBE_data['Date'])\nHYBE_data.dropna(axis  = 0, inplace = True)\n\nHYBE_data['3wma'] = HYBE_data['Price'].rolling(window = 15).mean()\nHYBE_data['20wma'] = HYBE_data['Price'].rolling(window = 100).mean()\nHYBE_data['50wma'] = HYBE_data['Price'].rolling(window = 250).mean()\n\nfig = px.line(HYBE_data, x='Date', y=['Price', '3wma', '20wma', '50wma'],\n              labels={'value': 'Daily Data', 'variable': 'Weekly Moving Average'},\n              title='Smoothing Moving Averages for HYBE Stock')\n\n# Show the plot\nfig.show()\n```\n\nThis plot depicts the smoothing moving average of HYBE stock prices. The smoothing windows I chose was 3-week, 20-week, and 50-week on the daily data. As we can see, the 3-week smoothing line is closely correlated with the actual prices, as expected. We can also see some crossings between the 3 smoothing moving averages. Primarily, we can see a crossing in September of 2021, where the 3-week SMA briefly crosses under and over the 20-week line. The crossing over of a shorter SMA, also called a golden cross, indicates that a postive trend in prices was to be expected, which is what occured. This is most likely due to the announcement of BTS performing at the 2021 Grammy Music Awards. Additionally, we can see a significant crossing again in April of 2022. This is when the 3-week and 20-week line cross under the 50-week. When a shorter term SMA cross under the longer SMA, we can infer a drop in stock prices, also called a Death Cross. This inevitably did happen, most likely due to talk of BTS's enlistment into the Korean military as a part of mandatory service, which was officially announced June of that year. \n\nNext, let's take a look at a few lag plots of data on itself as well ACF and PACF in order to identify possible signs of stationarity. \n\n### Lag-plot:\n```{r}\n#| warning: false\n#| code-fold: true\ngglagplot(HYBE_ts, do.lines=FALSE)+\n  ggtitle(\"Lag Plot for HYBE Stock Prices\")+\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n```\n\nThese lag plots show similar results to that of the globalization index. The forst four lags have a very strong positive linear correlation, suggesting autocorrelation amongst those lags. From lag 5 onwards, we still see a string linear correlation, however we can also see a small circular pattern forming in the lag plots, suggesting a possibility of single-cycle sinusodial data. \n\n### ACF & PACF:\n```{r}\n#| warning: false\n#| code-fold: true\nggAcf(HYBE_ts, lag.max = 30)+ggtitle(\"ACF Plot for HYBE Stock Prices\")\nggPacf(HYBE_ts, lag.max = 30)+ggtitle(\"PACF Plot for HYBE Stock Prices\")\n```\n\nSimilar to the globalization index, the ACF plot shows the present lag is significantly correlated with all other present lags in the plot, since all values are well above the siginificance bands. Additionally, the PACF shows a stationary plot, due to the PACF values being contained in the significance bands. Thus, we can say that there is in fact strong autocorrelation in this time series data, however correlation is not present within the residuals. \n\n### Dickey-Fuller Test:\n```{r}\n#| warning: false\n#| code-fold: true\nHYBE_test <- adf.test(HYBE_ts)\nprint(HYBE_test)\n```\n\nThe Dickey-Fuller Test resulted in a p-value of 0.5737. Since 0.5737 > 0.05, we can fail to reject the null hypothesis and say that the time series object is not stationary. \n\n### Stationary:\n\nGiven that the original data is not stationary through the Dickey-Fuller test, we will use the detrending and differencing methods to coerse the data to become stationary. \n\n```{r}\n#| warning: false\n#| code-fold: true\nfit = lm(HYBE_ts~time(HYBE_ts), na.action=NULL) \n\nplot1 <- ggAcf(HYBE_ts, lag.max = 30, main=\"Original Data: HYBE Stock Prices\")\nplot2 <- ggAcf(resid(fit), lag.max = 30, main=\"Detrended data\") \nplot3 <- ggAcf(diff(HYBE_ts), lag.max = 30, main=\"First Differenced Data\")\n\ngrid.arrange(plot1, plot2, plot3, ncol=3)\n```\n\nHowever, after trying both detrending and first difference methods, both result in ACF plots showing autocorrelation and non-stationary tendencies. Thus, we will try the second differencing approach. \n\n```{r}\n#| warning: false\n#| code-fold: true\nplot4 <- ggAcf(diff(diff(HYBE_ts)), lag.max = 30, main=\"Second Differenced Data\")\nplot4\n```\n\nWith the second difference, we were able to get the HYBE stock prices to become stationary. Therefore, we could also suggest the original data has quadratic trending behavior. \n\nThus, going forward, we can use the second difference of the HYBE stock prices for modeling. ","srcMarkdownNoYaml":"\n\nNow, I will be conducting a Time Series EDA analysis on the globalization indexes and the record label stock prices. Due to the structure of the other data, I cannot conduct further time series EDA on those sets. \n\n```{r}\n#| code-fold: true\n#| code-summary: 'Importing Libraries'\n#| warning: false\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(forecast)\nlibrary(astsa) \nlibrary(xts)\nlibrary(tseries)\nlibrary(fpp2)\nlibrary(fma)\nlibrary(lubridate)\nlibrary(tidyverse)\nlibrary(TSstudio)\nlibrary(quantmod)\nlibrary(tidyquant)\nlibrary(plotly)\nlibrary(ggplot2)\nlibrary(imputeTS)\nlibrary(gridExtra)\nlibrary(reticulate)\nuse_python(\"/usr/local/bin/python3\", require = T)\nknitr::knit_engines$set(python = reticulate::eng_python)\n```\n\n\n## Globalization: \nLet's begin by anaylzing globalization of the United States from 1970 to 2022. I will be using the general globalization index for this time series anaylsis. First I will begin by filtering the data and creating a time series object in R. This will allow us to plot the time series data for initial analysis. \n\n### Time Series plot: \n```{r}\n#| warning: false\n#| code-fold: true\n\n# Import dataset\nglobal <- read_csv('globalization.csv')\n\n# Filter information\nglobal <- global %>%\n  filter(country == 'United States') %>%\n  select(year, KOFGI) %>%\n  mutate(year = as.Date(year))\n\n# Create time series\nglobal_ts <-ts(global$KOFGI, star=decimal_date(as.Date(\"1970-01-01\", format = \"%Y-%m-%d\")), frequency = 1)\n\n# Create time series plot\nglobal_plot <- plot(as.ts(global_ts), main = \"Time Series of KOF Globalization Index within the United States\",\n                  xlab = 'Time', ylab = 'KOF Index')\n\n# Show plot\nggplotly(global_plot)\n\n```\n\nFrom the plot of the globalization index in the United States, we can see a strong positive upward trend. In terms of seasonality and cyclic patterns, we are unable to see such patterns in the plot. Additionally, we can see very slight peaks in the data in 1986 and 2009, however, they are not enough to conclude any patterns in the data. Thus,we can say this plot is neither additive nor multiplicative. \n\nNext, we'll take a look at a moving average smoothing plot to obtain some information on potential crossings.  \n\n### Moving Average Smoothing: \n```{python}\n#| code-fold: true\n#| code-summary: 'SMA Code'\n#| warning: false\n\n\nimport pandas as pd\nimport datetime\nimport plotly \nfrom datetime import datetime \nfrom pandas_datareader import data as pdr\nimport plotly.offline as pyo\nimport plotly.graph_objects as go \nfrom plotly.subplots import make_subplots\nimport plotly.express as px\n\nglobal_data = pd.read_csv('globalization.csv')\nglobal_data = global_data[global_data['country'] == 'United States']\nglobal_data['year'] = pd.to_datetime(global_data['year'], format='%Y')\n\nglobal_data['5yma'] = global_data['KOFGI'].rolling(window = 5).mean()\nglobal_data['10yma'] = global_data['KOFGI'].rolling(window = 10).mean()\nglobal_data['20yma'] = global_data['KOFGI'].rolling(window = 20).mean()\n\nfig = px.line(global_data, x='year', y=['KOFGI', '5yma', '10yma', '20yma'],\n              labels={'value': 'Yearly Data', 'variable': 'Moving Average'},\n              title='Yearly Data and Moving Averages for the Globalization Index')\n\n# Show the plot\nfig.show()\n```\n\nThis plot shows us the smoothing moving average for the yearly KOF globalization index data. The three types of smoothing I chose was 5-year, 10-year, and 20-year moving averages. As we can see in the graph, all smoothing lines show a positive upward trend across the time interval (the past 50 years). There is also no crossing between the smoothing lines, possibly indicating that the data had a constant upward trend with no seasonality or cyclical trends throughout. \n\nNext, let's take a look at a few lag plots of data on itself as well ACF and PACF in order to identify possible signs of stationarity. \n\n### Lag-plot: \n```{r}\n#| warning: false\n#| code-fold: true\ngglagplot(global_ts, do.lines=FALSE)+ggtitle(\"Lag Plot for the KOF Globalization Index\")\n```\n\nWe can see in lags 1,2, and 3 a very strong positive linear relationship, meaning a positive autocorrelation in the lags. From lag 4 and onward, the trend is still strongly positive, but less linear, suggesting a weaker autocorrelation. We also don't see any groupings in the lags, suggesting that there is no seasonality in the data. \n\n### ACF & PACF: \n```{r}\n#| warning: false\n#| code-fold: true\nggAcf(global_ts)+ggtitle(\"ACF Plot for Globalization Index\")\nggPacf(global_ts)+ggtitle(\"PACF Plot for Globalization Index\")\n```\n\nLooking at the ACF and PACF plots, we get a better understanding this time series. The ACF plot shows the present lag is significantly correlated with the first 12 years, after which it become significantly uncorrelated. Additionally, the PACF shows a stationary plot, due to the PACF values being contained in the significance bands. Thus, we can say that there is in fact strong autocorrelation in this time series data, however correlation is not present within the residuals. \n\n### Dickey-Fuller Test\n```{r}\n#| warning: false\n#| code-fold: true\nglobal_test <- adf.test(global_ts)\nprint(global_test)\n```\n\nThe Dickey-Fuller Test, with tests the alternative hypothesis that the time series is stationary, concluded a p-value of 0.99. Since 0.99 > 0.05, we do not have enough evidence and thus, fail to rejec the null hypothesis, meaning that the time series object is not stationary. \n\n### Stationary: \nTherefore, in order to obtain stationary data to runs an ARMA and AMRIMA model on, we will need to compare differenced and detrended data to find which approach produces stationary data. \n\n```{r}\n#| warning: false\n#| code-fold: true\nfit = lm(global_ts~time(global_ts), na.action=NULL) \n\nplot1 <- ggAcf(global_ts, 50, main=\"Original Data: Globalization Index\")\nplot2 <- ggAcf(resid(fit), 50, main=\"Detrended data\") \nplot3 <- ggAcf(diff(global_ts), 50, main=\"First Differenced Data\")\n\ngrid.arrange(plot1, plot2, plot3,ncol=3)\n```\n\nFrom this plot, we can clearly see that the first differenced data results in a stationary plot, with the ACF values inside the significance bands. Since the first difference was able to coerce the data to be stationary, we can also say that the original data was linearly trended. Thus, moving forward, we will use first differencing on the globalization index in order to model this value. \n\n## Stock Prices: Looking at HYBE Entertainment\n### Time Series plot:\n\nNext, since we saw, through the initial data visualization, the prevelance of Kpop and specifically BTS on the western music industry, we will take a look at HYBE stock prices through further time series EDA. \n\nPrimarily, we will clean our data such that missing dates corresponding to weekends and holidays where the stock market is closed will be estimated through exponential prediction. After which we will take the data and transform it into a time series object to plot. \n\n```{r}\n#| warning: false\n#| code-fold: true\noptions(\"getSymbols.warning4.0\"=FALSE)\noptions(\"getSymbols.yahoo.warning\"=FALSE)\n\n\nname <- getSymbols('352820.KS', from = \"2019-01-01\", to = \"2023-09-01\")\nHYBE <- data.frame(`352820.KS`$`352820.KS.Adjusted`)\nHYBE <- HYBE %>%\n  rownames_to_column(var = \"Date\") %>%\n  mutate(Date = as.Date(Date)) %>%\n  rename(Price = X352820.KS.Adjusted) %>%\n  mutate(Price = Price/1352.60)\n\nstart_date <- as.Date(\"2020-10-15\")\nend_date <- as.Date(\"2023-09-01\")\n\nall_dates <- data.frame(Date = seq(start_date, end_date, by = \"days\"))\n\nmerged_data <- all_dates %>%\n  left_join(HYBE, by = \"Date\")\n\nwrite.csv(merged_data, 'HYBE_cleaned_data.csv')\n\nimputed_time_series <- na_ma(merged_data, k = 4, weighting = \"exponential\")\ndf_HYBE <-data.frame(imputed_time_series)\ndf_HYBE$Date <-as.Date(df_HYBE$Date,format = \"%Y-%m-%d\")\n\n# Create time series\nHYBE_ts <-ts(df_HYBE$Price, star=decimal_date(as.Date(\"2020-10-15\", format = \"%Y-%m-%d\")), frequency = 365.25)\n\n# Create time series plot\nHYBE_plot <- plot(as.ts(HYBE_ts), main = \"Time Series of HYBE Stock Prices\",\n                  xlab = 'Time', ylab = 'Price (USD)')\n```\n\nUnlike the globalization index, the HYBE stock price fluctuates quite frequently in the smaller range of time. From 2021 to 2022, we can see a strong positive trend with slight seasonality. However, from 2022 onwards we see a sharp downward trend and with varying degrees of peaks. Thus, the uneven nature of the peaks and troughs results in data that is neither additive or multiplicative. Additionally, since the dataset is smaller, we cannot say anything of certain regarding cyclical patterns. \n\nNow, let's look at the SMA graph for HYBE stock to identify potential crossings. \n\n### Moving Average Smoothing: \n```{python}\n#| code-fold: true\n#| code-summary: 'SMA Code'\n#| warning: false\nHYBE_data = pd.read_csv('HYBE_cleaned_data.csv')\n\nHYBE_data.drop(HYBE_data.columns[0], axis=1, inplace = True)\nHYBE_data['Date'] = pd.to_datetime(HYBE_data['Date'])\nHYBE_data.dropna(axis  = 0, inplace = True)\n\nHYBE_data['3wma'] = HYBE_data['Price'].rolling(window = 15).mean()\nHYBE_data['20wma'] = HYBE_data['Price'].rolling(window = 100).mean()\nHYBE_data['50wma'] = HYBE_data['Price'].rolling(window = 250).mean()\n\nfig = px.line(HYBE_data, x='Date', y=['Price', '3wma', '20wma', '50wma'],\n              labels={'value': 'Daily Data', 'variable': 'Weekly Moving Average'},\n              title='Smoothing Moving Averages for HYBE Stock')\n\n# Show the plot\nfig.show()\n```\n\nThis plot depicts the smoothing moving average of HYBE stock prices. The smoothing windows I chose was 3-week, 20-week, and 50-week on the daily data. As we can see, the 3-week smoothing line is closely correlated with the actual prices, as expected. We can also see some crossings between the 3 smoothing moving averages. Primarily, we can see a crossing in September of 2021, where the 3-week SMA briefly crosses under and over the 20-week line. The crossing over of a shorter SMA, also called a golden cross, indicates that a postive trend in prices was to be expected, which is what occured. This is most likely due to the announcement of BTS performing at the 2021 Grammy Music Awards. Additionally, we can see a significant crossing again in April of 2022. This is when the 3-week and 20-week line cross under the 50-week. When a shorter term SMA cross under the longer SMA, we can infer a drop in stock prices, also called a Death Cross. This inevitably did happen, most likely due to talk of BTS's enlistment into the Korean military as a part of mandatory service, which was officially announced June of that year. \n\nNext, let's take a look at a few lag plots of data on itself as well ACF and PACF in order to identify possible signs of stationarity. \n\n### Lag-plot:\n```{r}\n#| warning: false\n#| code-fold: true\ngglagplot(HYBE_ts, do.lines=FALSE)+\n  ggtitle(\"Lag Plot for HYBE Stock Prices\")+\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n```\n\nThese lag plots show similar results to that of the globalization index. The forst four lags have a very strong positive linear correlation, suggesting autocorrelation amongst those lags. From lag 5 onwards, we still see a string linear correlation, however we can also see a small circular pattern forming in the lag plots, suggesting a possibility of single-cycle sinusodial data. \n\n### ACF & PACF:\n```{r}\n#| warning: false\n#| code-fold: true\nggAcf(HYBE_ts, lag.max = 30)+ggtitle(\"ACF Plot for HYBE Stock Prices\")\nggPacf(HYBE_ts, lag.max = 30)+ggtitle(\"PACF Plot for HYBE Stock Prices\")\n```\n\nSimilar to the globalization index, the ACF plot shows the present lag is significantly correlated with all other present lags in the plot, since all values are well above the siginificance bands. Additionally, the PACF shows a stationary plot, due to the PACF values being contained in the significance bands. Thus, we can say that there is in fact strong autocorrelation in this time series data, however correlation is not present within the residuals. \n\n### Dickey-Fuller Test:\n```{r}\n#| warning: false\n#| code-fold: true\nHYBE_test <- adf.test(HYBE_ts)\nprint(HYBE_test)\n```\n\nThe Dickey-Fuller Test resulted in a p-value of 0.5737. Since 0.5737 > 0.05, we can fail to reject the null hypothesis and say that the time series object is not stationary. \n\n### Stationary:\n\nGiven that the original data is not stationary through the Dickey-Fuller test, we will use the detrending and differencing methods to coerse the data to become stationary. \n\n```{r}\n#| warning: false\n#| code-fold: true\nfit = lm(HYBE_ts~time(HYBE_ts), na.action=NULL) \n\nplot1 <- ggAcf(HYBE_ts, lag.max = 30, main=\"Original Data: HYBE Stock Prices\")\nplot2 <- ggAcf(resid(fit), lag.max = 30, main=\"Detrended data\") \nplot3 <- ggAcf(diff(HYBE_ts), lag.max = 30, main=\"First Differenced Data\")\n\ngrid.arrange(plot1, plot2, plot3, ncol=3)\n```\n\nHowever, after trying both detrending and first difference methods, both result in ACF plots showing autocorrelation and non-stationary tendencies. Thus, we will try the second differencing approach. \n\n```{r}\n#| warning: false\n#| code-fold: true\nplot4 <- ggAcf(diff(diff(HYBE_ts)), lag.max = 30, main=\"Second Differenced Data\")\nplot4\n```\n\nWith the second difference, we were able to get the HYBE stock prices to become stationary. Therefore, we could also suggest the original data has quadratic trending behavior. \n\nThus, going forward, we can use the second difference of the HYBE stock prices for modeling. "},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["styles.css"],"toc":true,"output-file":"eda.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.450","theme":"minty","title":"Exploratory Data Analysis"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}