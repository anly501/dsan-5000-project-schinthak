{"title":"ARMA, ARIMA, and SARIMA Models","markdown":{"yaml":{"title":"ARMA, ARIMA, and SARIMA Models"},"headingText":"Globalization Index:","containsRefs":false,"markdown":"\n\nARMA and ARIMA Models are used in time-series in order to forecast the time series object at had. Thus, we will take a look at both the globalization index, the stock fluctuation of HYBE Co., Korean tourism, and popularity between KPOP and Western artists in order to forecast values and make future predictions. \n\nFrom our [Exploratory Data Analysis](https://shriya-chinthak.georgetown.domains/DSAN_5600/eda.html), we noticed the following information: \n\n* Prior to differencing, the ACF plot show several lags above the significance bands, indicating a **non-stationary** relationship. \n* The Augmented Dickey-Fuller Test confirmed that the data itself was **NOT stationary**.\n* **First Differencing** will be used since the data becomes stationary. \n\nThus, using this information, we will move on to creating the model: \n```{r}\n#| echo: false\n#| warning: false\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(forecast)\nlibrary(astsa) \nlibrary(xts)\nlibrary(tseries)\nlibrary(fpp2)\nlibrary(fma)\nlibrary(lubridate)\nlibrary(tidyverse)\nlibrary(TSstudio)\nlibrary(quantmod)\nlibrary(tidyquant)\nlibrary(plotly)\nlibrary(ggplot2)\nlibrary(imputeTS)\nlibrary(gridExtra)\nlibrary(reticulate)\nlibrary(readxl)\nuse_python(\"/usr/local/bin/python3\", require = T)\nknitr::knit_engines$set(python = reticulate::eng_python)\n```\n\n\n::: {.panel-tabset}\n\n## ACF and PACF\n\n* Since the ACF plot doesn't have any significant peaks, **q = 0**. \n\n* Since the PACF plot doesn't have any significant peaks, **p = 0**. \n\n* Since we differenced once, **d = 1**.\n\n```{r}\n#| echo: false\n#| warning: false\nglobal <- read_csv('globalization.csv')\n\n# Filter information\nglobal <- global %>%\n  filter(country == 'United States') %>%\n  select(year, KOFGI) %>%\n  mutate(year = as.Date(year))\n\n# Create time series\nglobal_ts <-ts(global$KOFGI, star=decimal_date(as.Date(\"1970-01-01\", format = \"%Y-%m-%d\")), frequency = 1)\n\nplot3 <- ggAcf(diff(global_ts), 50, main=\"First Differenced Data\")\nplot4 <- ggPacf(diff(global_ts), 50, main=\"First Differenced Data\")\ngrid.arrange(plot3, plot4, ncol=2)\n```\n\n## Manual ARIMA\nThus, we can easily view that the best model has values **p=0, d=1, and q=0**. \n```{r}\n#| code-fold: true \n#| code-summary: 'ARIMA Model'\n#| warning: false\n\nset.seed(123)\n\nd=1\ni=1\ntemp= data.frame()\nls=matrix(rep(NA,6*25),nrow=25) # roughly nrow = 5x2 (see below)\n\n\nfor (p in 0:4)# p=0,1,2,3,4 : 5\n{\n  for(q in 0:4)# q=0,1,2,3,4 :5\n  {\n    model<- Arima(global_ts,order=c(p,d,q),include.drift=TRUE) \n    ls[i,]= c(p,d,q,model$aic,model$bic,model$aicc)\n    i=i+1\n  }\n}\n\ntemp= as.data.frame(ls)\nnames(temp)= c(\"p\",\"d\",\"q\",\"AIC\",\"BIC\",\"AICc\")\n\n#temp\nknitr::kable(temp)\n\n```\n\n```{r}\n#| echo: false\nprint(\"AIC:\")\ntemp[which.min(temp$AIC),]\nprint(\"BIC:\")\ntemp[which.min(temp$BIC),]\nprint(\"AICc:\")\ntemp[which.min(temp$AICc),]\n```\n\n## Equation \n\nFrom the results of the `sarima()` function, we call say that the equation is as follows:\n\n\\begin{align}\nx_{t} = w_{t} -1w_{t-1} + 0.4805\n\\end{align}\n\nFrom the model diagonotics presented, we can also say that the ACF plot of residuals shows no significance, meaning the residuals are not correlated. Additionally, the p-values of the Ljung-Box statistic is much higher than the significance band, meaning that we fail to reject the null hypothesis and can say that the model is not autocorrelated. \n\n```{r}\n#| code-fold: true\nsarima(global_ts, 0, 1, 0)\n```\n\n## auto.arima()\n\n`auto.arima()` concluded that ARIMA(0,2,1) is the best model. However, due to it's greater AIC and BIC values, we have decided to stick if ARIMA(0,1,0). Thus, we will try forecasting both that model and ARIMA(0,1,0)\n\n```{r}\n#| code-fold: true\n#| warning: false\nauto.arima(global_ts)\n\nsarima(global_ts, 0, 2, 1)\n```\n\n## Forecasting\n```{r}\n#| code-fold: true \n#| code-summary: 'Forecasting'\n#| warning: false\nfit <- Arima(global_ts, order=c(0, 1, 0))\nautoplot(forecast(fit))\n```\n\n## Benchmark Comparison\n```{r}\n#| code-fold: true \n#| code-summary: 'Forecast comparison'\n#| warning: false\n\n\nautoplot(global_ts) +\n  autolayer(meanf(global_ts, h=11),\n            series=\"Mean\", PI=FALSE) +\n  autolayer(naive(global_ts, h=11),\n            series=\"Naïve\", PI=FALSE) +\n  autolayer(snaive(global_ts, h=11),\n            series=\"Seasonal naïve\", PI=FALSE) +\n  autolayer(forecast(fit, h=11),\n            series=\"Fit\", PI=FALSE) +\n  ggtitle(\"Forecasts for yearly globalization metric\") +\n  xlab(\"Year\") + ylab(\"KOF Index\") +\n  guides(colour=guide_legend(title=\"Forecast\"))\n```\n\n:::\n\nThus, from the ARIMA procedure, we found that our manual ARIMA approach was more effective in finding the model with the best AIC and BIC values than auto.arima(). From the forecast, we can clearly see that while globalization has been on an upward trend, it is predicted to level out in the next year. While this prediction is not promising, it does perform better than out benchmark fits.  \n\n---\n\n# Korean Tourism\n\nIn order to understand globalization within the USA through the lens on South Korea, we will need to also look at the tourism coming into SK from abroad. An example of this is using monthly air travel passeneger data into Incheon Airport, South Korea's largest international airport. Specifically, we'll be focusing on the number of passengers from international flights coming into South Korea for tourism as they best represent foreign interest of the nation. \n\nFrom our [Exploratory Data Analysis](https://shriya-chinthak.georgetown.domains/DSAN_5600/eda.html), we noticed the following information: \n\n* Prior to differencing, the ACF plot show several lags above the significance bands, indicating a **non-stationary** relationship. \n* **Season + First Differencing** resulted in the data being stationary. \n\n::: {.panel-tabset}\n\n## ACF and PACF\n\nFrom these plots, we can say that q = 2, p = 2, 4, d = 1, Q = 1, and P = 1. \n\n```{r}\n#| warning: false\n#| code-fold: true\n\n\nsk_passengers <- read_xlsx('raw_data/sk_passenger_arrivals.xlsx')\n\nsk_passengers <- sk_passengers %>%\n  unite(date, year, month, sep = '-') %>%\n  mutate(date = as.Date(paste(date, '01', sep = '-'))) %>%\n  filter(year(date) < 2020) #In order to avoid the anomaly of the 2020 pandemic\n\nair_travel_ts <- ts(sk_passengers$Passengers, start = c(2010, 10), \n                    frequency = 12)\n\nggAcf(air_travel_ts %>% diff() %>% diff(12), lag.max = 30, main=\"Seasonal Differenced + First Differenced ACF\")\nggPacf(air_travel_ts %>% diff() %>% diff(12), lag.max = 30, main=\"Seasonal Differenced + First Differenced PACF\")\n\n```\n\n## Manual SARIMA\nMoving on with model **ARIMA(0,1,2)x(0,1,1)[12]** due to the lowest AIC, AICc, and BIC values. \n\n```{r}\n#| code-fold: true\n\n#write a function\nSARIMA.c=function(p1,p2,q1,q2,P1,P2,Q1,Q2,data){\n  \n  temp=c()\n  d=1\n  D=1\n  s=12\n  \n  i=1\n  temp= data.frame()\n  ls=matrix(rep(NA,9*35),nrow=35)\n  for (p in p1:p2)\n  {\n    for(q in q1:q2)\n    {\n      for(P in P1:P2)\n      {\n        for(Q in Q1:Q2)\n        {\n          if(p+d+q+P+D+Q<=9)\n          {\n            model<- Arima(data,order=c(p-1,d,q-1),seasonal=c(P-1,D,Q-1))\n            ls[i,]= c(p-1,d,q-1,P-1,D,Q-1,model$aic,model$bic,model$aicc)\n            i=i+1\n          }\n        }\n      }\n    }\n  }\n  \n  temp= as.data.frame(ls)\n  names(temp)= c(\"p\",\"d\",\"q\",\"P\",\"D\",\"Q\",\"AIC\",\"BIC\",\"AICc\")\n  temp\n}\n\noutput=SARIMA.c(p1=1,p2=5,q1=1,q2=3,P1=1,P2=3,Q1=1,Q2=3,data=air_travel_ts)\nknitr::kable(output)\n\noutput[which.min(output$AIC),]\noutput[which.min(output$BIC),]\noutput[which.min(output$AICc),]\n```\n\n## auto.arima()\n```{r}\n#| code-fold: true\nauto.arima(air_travel_ts)\n```\n\n## Equation\nThis model seems to be a goof fit for a number of reasons. Primarily, the ACF plot shows almost no correlation, indicating that the model has harnessed everything that left is white noise. This indicates a good model fit. Additionally, the Ljung-Box statistic shows almost no autocorrelation within the model. Lastly, all coefficients within the table are significant. \n\n\\begin{align}\n(1 - \\beta)(1 - \\beta^{12}) (Y_t - \\mu) = (1 + 0.2648\\beta + 0.4423\\beta^2)(1 - 0.6406\\beta^{12}) \\epsilon_t\n\\end{align}\n\n\n```{r}\n#| code-fold: true\n\nset.seed(123)\nmodel_output <- capture.output(sarima(air_travel_ts, 0,1,2,0,1,1,12))\ncat(model_output[28:60], model_output[length(model_output)], sep = \"\\n\") \n```\n\n## Fitting\n```{r}\n#| code-fold: true\nfit <- Arima(air_travel_ts, order=c(0,1,2), seasonal=c(0,1,1))\nsummary(fit)\n```\n\n## Forecasting\n```{r}\n#| code-fold: true\nsarima.for(air_travel_ts, 60, 0,1,2,0,1,1,12)\n```\n\n:::\n\nSimilar to out globalization index, we can see that the manual approach to find the best model was better than auto.arima() since the resulting model had a better AIC, BIC, AICc values. Our forecast shows a positive upwards trend in international passenger arrivals into Incheon Airport, South Korea. Please note, this forecast shows five years into the future if the COVID-19 pandemic didn't cause any anomalies within air travel. However, even knowing that the actual data isn't the same, we can approximate that the travel industry would recover in a similar pattern, with a positive trend of people coming into Korea. Thus, this furthers the narrative of globalization, and specifically, Korean culture reaching outside its country's borders into the West. \n\n---\n\n# Forecasting HYBE\n\nAs we've seen thus far, BTS, a group under HYBE, seems to have far better success than other KPOP groups in the West. However, with their recent announcement of mandatory military enlightment, we want to see how HYBE stock will forecast in the coming months.\n\nFrom our [Exploratory Data Analysis](https://shriya-chinthak.georgetown.domains/DSAN_5600/eda.html), we noticed the following information: \n\n* Prior to differencing, the ACF plot show several lags above the significance bands, indicating a **non-stationary** relationship. \n* **Second Differencing** resulted in the data being stationary.\n\n::: {.panel-tabset}\n\n## ACF & PACF\n```{r}\n#| warning: false\n#| code-fold: true\noptions(\"getSymbols.warning4.0\"=FALSE)\noptions(\"getSymbols.yahoo.warning\"=FALSE)\n\n\nname <- getSymbols('352820.KS', from = \"2019-01-01\", to = \"2023-09-01\")\nHYBE <- data.frame(`352820.KS`$`352820.KS.Adjusted`)\nHYBE <- HYBE %>%\n  rownames_to_column(var = \"Date\") %>%\n  mutate(Date = as.Date(Date)) %>%\n  rename(Price = X352820.KS.Adjusted) %>%\n  mutate(Price = Price/1352.60)\n\nstart_date <- as.Date(\"2020-10-15\")\nend_date <- as.Date(\"2023-09-01\")\n\nall_dates <- data.frame(Date = seq(start_date, end_date, by = \"days\"))\n\nmerged_data <- all_dates %>%\n  left_join(HYBE, by = \"Date\")\n\nimputed_time_series <- na_ma(merged_data, k = 4, weighting = \"exponential\")\ndf_HYBE <-data.frame(imputed_time_series)\ndf_HYBE$Date <-as.Date(df_HYBE$Date,format = \"%Y-%m-%d\")\n\nwrite.csv(df_HYBE, 'cleaned_data/HYBE_cleaned_data.csv')\n\n# Create time series\nHYBE_ts <-ts(df_HYBE$Price, star=decimal_date(as.Date(\"2020-10-15\", format = \"%Y-%m-%d\")), frequency = 365.25)\n\nggAcf(diff(diff(HYBE_ts)), lag.max = 30, main=\"Second Differenced Data\")\nggPacf(diff(diff(HYBE_ts)), lag.max = 30, main=\"Second Differenced Data\")\n```\n\n## Manual ARIMA\nThus, we can easily view that the best model has values **p=1,2,3,4, d=2, and q=1**. \n```{r}\n#| code-fold: true \n#| code-summary: 'ARIMA Model'\n#| warning: false\n\nset.seed(123)\n\nd=2\ni=1\ntemp= data.frame()\nls=matrix(rep(NA,6*25),nrow=25) # roughly nrow = 5x2 (see below)\n\n\nfor (p in 0:4)# p=0,1,2,3,4 : 5\n{\n  for(q in 0:4)# q=0,1,2,3,4 :5\n  {\n    model<- Arima(HYBE_ts,order=c(p,d,q),include.drift=TRUE) \n    ls[i,]= c(p,d,q,model$aic,model$bic,model$aicc)\n    i=i+1\n  }\n}\n\ntemp= as.data.frame(ls)\nnames(temp)= c(\"p\",\"d\",\"q\",\"AIC\",\"BIC\",\"AICc\")\n\n#temp\nknitr::kable(temp)\n```\n\n```{r}\n#| echo: false\nprint(\"AIC:\")\ntemp[which.min(temp$AIC),]\nprint(\"BIC:\")\ntemp[which.min(temp$BIC),]\nprint(\"AICc:\")\ntemp[which.min(temp$AICc),]\n```\n\n\n## Equation \n\nFrom the results of the `sarima()` function, we call say that the equation is as follows:\n\n\\begin{align}\n(1 - 0.9590\\beta - 0.4301\\beta^2)(1 - \\beta)(1 - \\beta)^2 (Y_t - \\mu) = (1 - 2.1072\\beta - 1.7438\\beta^2 + 0.6367\\beta^3) \\epsilon_t\n\\end{align}\n\n```{r}\n#| code-fold: true\nsarima(HYBE_ts, 2, 2, 3)\n```\n\n\n## auto.arima()\n\n`auto.arima()` concluded that ARIMA(4,1,2) is the best model. Comparing this to ARIMA(2,2,3), we can see that the AIC, BIC, and AICc values are much better. Additionally, the Ljung-Box statistic shows almost no autocorrelation within the model. \n\n```{r}\n#| code-fold: true\n#| warning: false\nauto.arima(HYBE_ts)\n\nsarima(HYBE_ts, 4, 1, 2)\n```\n\n## Forecasting\n```{r}\n#| code-fold: true \n#| code-summary: 'Forecasting'\n#| warning: false\nfit <- Arima(HYBE_ts, order=c(4, 1, 2))\nautoplot(forecast(fit, h = 365))\n```\n\n## Benchmark Comparison\n```{r}\n#| code-fold: true \n#| code-summary: 'Forecast comparison'\n#| warning: false\n\n\nautoplot(HYBE_ts) +\n  autolayer(meanf(HYBE_ts, h=365),\n            series=\"Mean\", PI=FALSE) +\n  autolayer(naive(HYBE_ts, h=365),\n            series=\"Naïve\", PI=FALSE) +\n  autolayer(snaive(HYBE_ts, h=365),\n            series=\"Seasonal naïve\", PI=FALSE) +\n  autolayer(forecast(fit, h=365),\n            series=\"Fit\", PI=FALSE) +\n  ggtitle(\"Forecasts for HYBE Stock Price\") +\n  xlab(\"Year\") + ylab(\"Price (USD)\") +\n  guides(colour=guide_legend(title=\"Forecast\"))\n```\n\n:::\n\nFrom the manual approach, we can also say that the ACF plot of residuals shows no significance, meaning the residuals are not correlated. Additionally, the p-values of the Ljung-Box statistic is on the lower side, however, we will continue and see whether auto.arima() creates a better model. Thus, after forecasting ARIMA(4,1,2), we can see that the forecast predicts a consistent stock price for the next year. Obviously, this doesn't seem feasible, as stock prices are constantly changing. However, what this does tell us is that there isn't an immediate positive trend in HYBE stock to say that the prediction would be upward. Therefore, we'll move forward and see how other KPOP labels and Western record labels may effect volitilaty and unpredictability of HYBE's future. \n\n--- \n\n# Popularity: KPOP\n\nIn order to get a better understanding of the popularity of KPOP as the years progress, we will create a ARMA model to forecast.\n\nFrom our [Exploratory Data Analysis](https://shriya-chinthak.georgetown.domains/DSAN_5600/eda.html), we noticed the following information: \n\n* Our original data, when plotted in an ACF and PACF plot, returned lags well within the significance bounds, meaning that the data was **stationary without differencing**. \n\n::: {.panel-tabset}\n\n## ACF & PACF \n```{r}\n#| code-fold: true\n\nkpop_data <- read.csv(\"cleaned_data/kpop_popularity.csv\")\nkpop_ts <- ts(kpop_data$popularity, frequency = 1)\n\nggAcf(kpop_ts)+ggtitle(\"ACF Plot for Popularity Score of KPOP Artists\")\nggPacf(kpop_ts)+ggtitle(\"PACF Plot for Popularity Score of KPOP Artists\")\n```\n\n## Manual ARMA\n```{r}\n#| code-fold: true\n#| warning: true\n\nset.seed(123)\n\nd=1\ni=1\ntemp= data.frame()\nls=matrix(rep(NA,6*25),nrow=25) # roughly nrow = 5x2 (see below)\n\n\nfor (p in 0:4)# p=0,1,2,3,4 : 5\n{\n  for(q in 0:4)# q=0,1,2,3,4 :5\n  {\n    model<- Arima(kpop_ts,order=c(p,d,q),include.drift=TRUE) \n    ls[i,]= c(p,d,q,model$aic,model$bic,model$aicc)\n    i=i+1\n  }\n}\n\ntemp= as.data.frame(ls)\nnames(temp)= c(\"p\",\"d\",\"q\",\"AIC\",\"BIC\",\"AICc\")\n\n#temp\nknitr::kable(temp)\n\n```\n\n```{r}\n#| echo: false\nprint(\"AIC:\")\ntemp[which.min(temp$AIC),]\nprint(\"BIC:\")\ntemp[which.min(temp$BIC),]\nprint(\"AICc:\")\ntemp[which.min(temp$AICc),]\n```\n\n\n## Equation\nThe resulting model is a constant function as a result of model selection. Unfortunelty, due to the lack of data points, we are unable to output the model diagnostics of the ARMA(0,0) model. Using the auto.arima() function, the equation for the model is written as follows. \n\n\\begin{align}\nx_{t} = w_{t} + 77.3352\n\\end{align}\n\n## auto.arima()\nThe auto.arima() function confirms our ACF and PACF plots with the model ARIMA(0,0,0)\n\n```{r}\n#| code-fold: true\nauto.arima(kpop_ts)\n```\n\n## Forecast\n\n```{r}\n#| code-fold: true\nfit <- Arima(kpop_ts, order=c(0, 0, 0))\nautoplot(forecast(fit))\n```\n\n## Benchmark Comparison\n\n```{r}\n#| code-fold: true\nautoplot(kpop_ts) +\n  autolayer(meanf(kpop_ts, h=11),\n            series=\"Mean\", PI=FALSE) +\n  autolayer(naive(kpop_ts, h=11),\n            series=\"Naïve\", PI=FALSE) +\n  autolayer(snaive(kpop_ts, h=11),\n            series=\"Seasonal naïve\", PI=FALSE) +\n  autolayer(forecast(fit, h=11),\n            series=\"Fit\", PI=FALSE) +\n  ggtitle(\"Forecasts for Yearly Average Popularity Score of KPOP Artists\") +\n  xlab(\"Year\") + ylab(\"Popularity Score\") +\n  guides(colour=guide_legend(title=\"Forecast\"))\n```\n\n:::\n\nSince we cannot see any siginificant lags in the ACF and PACF, we'll need to use a ARMA(0,0,0) model. However, running a manual and auto.arima() can help to decide the best approach. Through the manual approach, we found ARIMA(0,1,0) the best purely based on AIC and BIC. However, because this data cannot be differenced, ARIMA(0,0,0) is the best option, with auto.arima() solidfying this notion. As a result, the forecast is simply the mean value of the popularity, which is not a good indicator of the future forecast. The lack of data points unfortunelty prevented an in depth prediction, however, we can note that as as KPOP continues to be streamed, we will continue to see rising popularity. \n\n---\n\n# Popularity: Western\n\nIn order to get a better understanding of the popularity of Western artists as the years progress, we will create an ARMA model to forecast. As a reminder, due to the new Spotify API regulations, popularity scores are not public for all songs. Therefore, to use the metric we've extrapolated and averaged the scores. For more details, please [Data Visualizations](https://shriya-chinthak.georgetown.domains/DSAN_5600/data-visualization.html). \n\nFrom our [Exploratory Data Analysis](https://shriya-chinthak.georgetown.domains/DSAN_5600/eda.html), we noticed the following information: \n\n* Our original data, when plotted in an ACF and PACF plot, returned lags well within the significance bounds, meaning that the data was **stationary without differencing**. \n\n::: {.panel-tabset}\n\n## ACF & PACF\n\n```{r}\n#| code-fold: true\n\nwestern_data <- read.csv(\"cleaned_data/western_popularity.csv\")\nwestern_ts <- ts(western_data$popularity, frequency = 1)\n\nggAcf(western_ts)+ggtitle(\"ACF Plot for Popularity Score of Western Artists\")\nggPacf(western_ts)+ggtitle(\"PACF Plot for Popularity Score of Western Artists\")\n\n```\n\n## Manual ARIMA\n\n```{r}\n#| code-fold: true\n#| warning: true\n\nset.seed(123)\n\nd=1\ni=1\ntemp= data.frame()\nls=matrix(rep(NA,6*25),nrow=25) # roughly nrow = 5x2 (see below)\n\n\nfor (p in 0:4)# p=0,1,2,3,4 : 5\n{\n  for(q in 0:4)# q=0,1,2,3,4 :5\n  {\n    model<- Arima(western_ts,order=c(p,d,q),include.drift=TRUE) \n    ls[i,]= c(p,d,q,model$aic,model$bic,model$aicc)\n    i=i+1\n  }\n}\n\ntemp= as.data.frame(ls)\nnames(temp)= c(\"p\",\"d\",\"q\",\"AIC\",\"BIC\",\"AICc\")\n\n#temp\nknitr::kable(temp)\n\n```\n\n```{r}\n#| echo: false\nprint(\"AIC:\")\ntemp[which.min(temp$AIC),]\nprint(\"BIC:\")\ntemp[which.min(temp$BIC),]\nprint(\"AICc:\")\ntemp[which.min(temp$AICc),]\n```\n\n## Model Diagnotics\n\nThe manual approach suggested the model ARIMA(0,1,2) based on the lowest AIC and BIC values. After running the model diagnostics, we have the following. \n\n```{r}\n#| code-fold: true\nsarima(western_ts, 0, 1, 2)\n```\n\n## auto.arima()\nCross referencing with auto.arima() resulted in the model ARIMA(0,1,1). Through a model diagnostics analysis, we can see that while the AIC and BIC values are slightly higher, the Ljung-Box statistic p-values are much higher than the significance band, meaning that we fail to reject the null hypothesis and can say that the model is not autocorrelated. Therefore, we'll move forward with this model. \n\n\\begin{align}\n(1 - B)(Y_t - \\mu) = -0.7565 \\epsilon_t\n\\end{align}\n\n```{r}\n#| code-fold: true\nauto.arima(western_ts) #produced 0,1,1\nsarima(western_ts, 0, 1, 1)\n```\n\n## Forecast\n\n```{r}\n#| code-fold: true\nfit <- Arima(western_ts, order=c(0, 1, 1))\nautoplot(forecast(fit))\n```\n\n## Benchmark Comparison\n\n```{r}\n#| code-fold: true\n\n\nautoplot(western_ts) +\n  autolayer(meanf(western_ts, h=11),\n            series=\"Mean\", PI=FALSE) +\n  autolayer(naive(western_ts, h=11),\n            series=\"Naïve\", PI=FALSE) +\n  autolayer(snaive(western_ts, h=11),\n            series=\"Seasonal naïve\", PI=FALSE) +\n  autolayer(forecast(fit, h=11),\n            series=\"Fit\", PI=FALSE) +\n  ggtitle(\"Forecasts for Yearly Average Popularity Score of Western Artists\") +\n  xlab(\"Year\") + ylab(\"Popularity Score\") +\n  guides(colour=guide_legend(title=\"Forecast\"))\n```\n\n:::\n\nFor Western artists we saw that auto.arima() found a better model than our manual approach. The forecast shows a constant metric for the popularity score. Unfortunelty, this model, like the popularity score for KPOP, was not able to meet benchmark standards, simply due to the lack of data points. \n\nFor future analysis of popularity, we must investigate another outlet as opposed to the Spotify metric due to the new API regulations. A different metric with a string database would allow us to properly predict popularity based on genre and artist. However, what we can say is that popularity for both Western and KPOP artists fluctuate. To further estimate popularity of an artists, we must try to look at their musical characteristics and how this can predict popularity in time. \n\n","srcMarkdownNoYaml":"\n\nARMA and ARIMA Models are used in time-series in order to forecast the time series object at had. Thus, we will take a look at both the globalization index, the stock fluctuation of HYBE Co., Korean tourism, and popularity between KPOP and Western artists in order to forecast values and make future predictions. \n\n## Globalization Index: \nFrom our [Exploratory Data Analysis](https://shriya-chinthak.georgetown.domains/DSAN_5600/eda.html), we noticed the following information: \n\n* Prior to differencing, the ACF plot show several lags above the significance bands, indicating a **non-stationary** relationship. \n* The Augmented Dickey-Fuller Test confirmed that the data itself was **NOT stationary**.\n* **First Differencing** will be used since the data becomes stationary. \n\nThus, using this information, we will move on to creating the model: \n```{r}\n#| echo: false\n#| warning: false\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(forecast)\nlibrary(astsa) \nlibrary(xts)\nlibrary(tseries)\nlibrary(fpp2)\nlibrary(fma)\nlibrary(lubridate)\nlibrary(tidyverse)\nlibrary(TSstudio)\nlibrary(quantmod)\nlibrary(tidyquant)\nlibrary(plotly)\nlibrary(ggplot2)\nlibrary(imputeTS)\nlibrary(gridExtra)\nlibrary(reticulate)\nlibrary(readxl)\nuse_python(\"/usr/local/bin/python3\", require = T)\nknitr::knit_engines$set(python = reticulate::eng_python)\n```\n\n\n::: {.panel-tabset}\n\n## ACF and PACF\n\n* Since the ACF plot doesn't have any significant peaks, **q = 0**. \n\n* Since the PACF plot doesn't have any significant peaks, **p = 0**. \n\n* Since we differenced once, **d = 1**.\n\n```{r}\n#| echo: false\n#| warning: false\nglobal <- read_csv('globalization.csv')\n\n# Filter information\nglobal <- global %>%\n  filter(country == 'United States') %>%\n  select(year, KOFGI) %>%\n  mutate(year = as.Date(year))\n\n# Create time series\nglobal_ts <-ts(global$KOFGI, star=decimal_date(as.Date(\"1970-01-01\", format = \"%Y-%m-%d\")), frequency = 1)\n\nplot3 <- ggAcf(diff(global_ts), 50, main=\"First Differenced Data\")\nplot4 <- ggPacf(diff(global_ts), 50, main=\"First Differenced Data\")\ngrid.arrange(plot3, plot4, ncol=2)\n```\n\n## Manual ARIMA\nThus, we can easily view that the best model has values **p=0, d=1, and q=0**. \n```{r}\n#| code-fold: true \n#| code-summary: 'ARIMA Model'\n#| warning: false\n\nset.seed(123)\n\nd=1\ni=1\ntemp= data.frame()\nls=matrix(rep(NA,6*25),nrow=25) # roughly nrow = 5x2 (see below)\n\n\nfor (p in 0:4)# p=0,1,2,3,4 : 5\n{\n  for(q in 0:4)# q=0,1,2,3,4 :5\n  {\n    model<- Arima(global_ts,order=c(p,d,q),include.drift=TRUE) \n    ls[i,]= c(p,d,q,model$aic,model$bic,model$aicc)\n    i=i+1\n  }\n}\n\ntemp= as.data.frame(ls)\nnames(temp)= c(\"p\",\"d\",\"q\",\"AIC\",\"BIC\",\"AICc\")\n\n#temp\nknitr::kable(temp)\n\n```\n\n```{r}\n#| echo: false\nprint(\"AIC:\")\ntemp[which.min(temp$AIC),]\nprint(\"BIC:\")\ntemp[which.min(temp$BIC),]\nprint(\"AICc:\")\ntemp[which.min(temp$AICc),]\n```\n\n## Equation \n\nFrom the results of the `sarima()` function, we call say that the equation is as follows:\n\n\\begin{align}\nx_{t} = w_{t} -1w_{t-1} + 0.4805\n\\end{align}\n\nFrom the model diagonotics presented, we can also say that the ACF plot of residuals shows no significance, meaning the residuals are not correlated. Additionally, the p-values of the Ljung-Box statistic is much higher than the significance band, meaning that we fail to reject the null hypothesis and can say that the model is not autocorrelated. \n\n```{r}\n#| code-fold: true\nsarima(global_ts, 0, 1, 0)\n```\n\n## auto.arima()\n\n`auto.arima()` concluded that ARIMA(0,2,1) is the best model. However, due to it's greater AIC and BIC values, we have decided to stick if ARIMA(0,1,0). Thus, we will try forecasting both that model and ARIMA(0,1,0)\n\n```{r}\n#| code-fold: true\n#| warning: false\nauto.arima(global_ts)\n\nsarima(global_ts, 0, 2, 1)\n```\n\n## Forecasting\n```{r}\n#| code-fold: true \n#| code-summary: 'Forecasting'\n#| warning: false\nfit <- Arima(global_ts, order=c(0, 1, 0))\nautoplot(forecast(fit))\n```\n\n## Benchmark Comparison\n```{r}\n#| code-fold: true \n#| code-summary: 'Forecast comparison'\n#| warning: false\n\n\nautoplot(global_ts) +\n  autolayer(meanf(global_ts, h=11),\n            series=\"Mean\", PI=FALSE) +\n  autolayer(naive(global_ts, h=11),\n            series=\"Naïve\", PI=FALSE) +\n  autolayer(snaive(global_ts, h=11),\n            series=\"Seasonal naïve\", PI=FALSE) +\n  autolayer(forecast(fit, h=11),\n            series=\"Fit\", PI=FALSE) +\n  ggtitle(\"Forecasts for yearly globalization metric\") +\n  xlab(\"Year\") + ylab(\"KOF Index\") +\n  guides(colour=guide_legend(title=\"Forecast\"))\n```\n\n:::\n\nThus, from the ARIMA procedure, we found that our manual ARIMA approach was more effective in finding the model with the best AIC and BIC values than auto.arima(). From the forecast, we can clearly see that while globalization has been on an upward trend, it is predicted to level out in the next year. While this prediction is not promising, it does perform better than out benchmark fits.  \n\n---\n\n# Korean Tourism\n\nIn order to understand globalization within the USA through the lens on South Korea, we will need to also look at the tourism coming into SK from abroad. An example of this is using monthly air travel passeneger data into Incheon Airport, South Korea's largest international airport. Specifically, we'll be focusing on the number of passengers from international flights coming into South Korea for tourism as they best represent foreign interest of the nation. \n\nFrom our [Exploratory Data Analysis](https://shriya-chinthak.georgetown.domains/DSAN_5600/eda.html), we noticed the following information: \n\n* Prior to differencing, the ACF plot show several lags above the significance bands, indicating a **non-stationary** relationship. \n* **Season + First Differencing** resulted in the data being stationary. \n\n::: {.panel-tabset}\n\n## ACF and PACF\n\nFrom these plots, we can say that q = 2, p = 2, 4, d = 1, Q = 1, and P = 1. \n\n```{r}\n#| warning: false\n#| code-fold: true\n\n\nsk_passengers <- read_xlsx('raw_data/sk_passenger_arrivals.xlsx')\n\nsk_passengers <- sk_passengers %>%\n  unite(date, year, month, sep = '-') %>%\n  mutate(date = as.Date(paste(date, '01', sep = '-'))) %>%\n  filter(year(date) < 2020) #In order to avoid the anomaly of the 2020 pandemic\n\nair_travel_ts <- ts(sk_passengers$Passengers, start = c(2010, 10), \n                    frequency = 12)\n\nggAcf(air_travel_ts %>% diff() %>% diff(12), lag.max = 30, main=\"Seasonal Differenced + First Differenced ACF\")\nggPacf(air_travel_ts %>% diff() %>% diff(12), lag.max = 30, main=\"Seasonal Differenced + First Differenced PACF\")\n\n```\n\n## Manual SARIMA\nMoving on with model **ARIMA(0,1,2)x(0,1,1)[12]** due to the lowest AIC, AICc, and BIC values. \n\n```{r}\n#| code-fold: true\n\n#write a function\nSARIMA.c=function(p1,p2,q1,q2,P1,P2,Q1,Q2,data){\n  \n  temp=c()\n  d=1\n  D=1\n  s=12\n  \n  i=1\n  temp= data.frame()\n  ls=matrix(rep(NA,9*35),nrow=35)\n  for (p in p1:p2)\n  {\n    for(q in q1:q2)\n    {\n      for(P in P1:P2)\n      {\n        for(Q in Q1:Q2)\n        {\n          if(p+d+q+P+D+Q<=9)\n          {\n            model<- Arima(data,order=c(p-1,d,q-1),seasonal=c(P-1,D,Q-1))\n            ls[i,]= c(p-1,d,q-1,P-1,D,Q-1,model$aic,model$bic,model$aicc)\n            i=i+1\n          }\n        }\n      }\n    }\n  }\n  \n  temp= as.data.frame(ls)\n  names(temp)= c(\"p\",\"d\",\"q\",\"P\",\"D\",\"Q\",\"AIC\",\"BIC\",\"AICc\")\n  temp\n}\n\noutput=SARIMA.c(p1=1,p2=5,q1=1,q2=3,P1=1,P2=3,Q1=1,Q2=3,data=air_travel_ts)\nknitr::kable(output)\n\noutput[which.min(output$AIC),]\noutput[which.min(output$BIC),]\noutput[which.min(output$AICc),]\n```\n\n## auto.arima()\n```{r}\n#| code-fold: true\nauto.arima(air_travel_ts)\n```\n\n## Equation\nThis model seems to be a goof fit for a number of reasons. Primarily, the ACF plot shows almost no correlation, indicating that the model has harnessed everything that left is white noise. This indicates a good model fit. Additionally, the Ljung-Box statistic shows almost no autocorrelation within the model. Lastly, all coefficients within the table are significant. \n\n\\begin{align}\n(1 - \\beta)(1 - \\beta^{12}) (Y_t - \\mu) = (1 + 0.2648\\beta + 0.4423\\beta^2)(1 - 0.6406\\beta^{12}) \\epsilon_t\n\\end{align}\n\n\n```{r}\n#| code-fold: true\n\nset.seed(123)\nmodel_output <- capture.output(sarima(air_travel_ts, 0,1,2,0,1,1,12))\ncat(model_output[28:60], model_output[length(model_output)], sep = \"\\n\") \n```\n\n## Fitting\n```{r}\n#| code-fold: true\nfit <- Arima(air_travel_ts, order=c(0,1,2), seasonal=c(0,1,1))\nsummary(fit)\n```\n\n## Forecasting\n```{r}\n#| code-fold: true\nsarima.for(air_travel_ts, 60, 0,1,2,0,1,1,12)\n```\n\n:::\n\nSimilar to out globalization index, we can see that the manual approach to find the best model was better than auto.arima() since the resulting model had a better AIC, BIC, AICc values. Our forecast shows a positive upwards trend in international passenger arrivals into Incheon Airport, South Korea. Please note, this forecast shows five years into the future if the COVID-19 pandemic didn't cause any anomalies within air travel. However, even knowing that the actual data isn't the same, we can approximate that the travel industry would recover in a similar pattern, with a positive trend of people coming into Korea. Thus, this furthers the narrative of globalization, and specifically, Korean culture reaching outside its country's borders into the West. \n\n---\n\n# Forecasting HYBE\n\nAs we've seen thus far, BTS, a group under HYBE, seems to have far better success than other KPOP groups in the West. However, with their recent announcement of mandatory military enlightment, we want to see how HYBE stock will forecast in the coming months.\n\nFrom our [Exploratory Data Analysis](https://shriya-chinthak.georgetown.domains/DSAN_5600/eda.html), we noticed the following information: \n\n* Prior to differencing, the ACF plot show several lags above the significance bands, indicating a **non-stationary** relationship. \n* **Second Differencing** resulted in the data being stationary.\n\n::: {.panel-tabset}\n\n## ACF & PACF\n```{r}\n#| warning: false\n#| code-fold: true\noptions(\"getSymbols.warning4.0\"=FALSE)\noptions(\"getSymbols.yahoo.warning\"=FALSE)\n\n\nname <- getSymbols('352820.KS', from = \"2019-01-01\", to = \"2023-09-01\")\nHYBE <- data.frame(`352820.KS`$`352820.KS.Adjusted`)\nHYBE <- HYBE %>%\n  rownames_to_column(var = \"Date\") %>%\n  mutate(Date = as.Date(Date)) %>%\n  rename(Price = X352820.KS.Adjusted) %>%\n  mutate(Price = Price/1352.60)\n\nstart_date <- as.Date(\"2020-10-15\")\nend_date <- as.Date(\"2023-09-01\")\n\nall_dates <- data.frame(Date = seq(start_date, end_date, by = \"days\"))\n\nmerged_data <- all_dates %>%\n  left_join(HYBE, by = \"Date\")\n\nimputed_time_series <- na_ma(merged_data, k = 4, weighting = \"exponential\")\ndf_HYBE <-data.frame(imputed_time_series)\ndf_HYBE$Date <-as.Date(df_HYBE$Date,format = \"%Y-%m-%d\")\n\nwrite.csv(df_HYBE, 'cleaned_data/HYBE_cleaned_data.csv')\n\n# Create time series\nHYBE_ts <-ts(df_HYBE$Price, star=decimal_date(as.Date(\"2020-10-15\", format = \"%Y-%m-%d\")), frequency = 365.25)\n\nggAcf(diff(diff(HYBE_ts)), lag.max = 30, main=\"Second Differenced Data\")\nggPacf(diff(diff(HYBE_ts)), lag.max = 30, main=\"Second Differenced Data\")\n```\n\n## Manual ARIMA\nThus, we can easily view that the best model has values **p=1,2,3,4, d=2, and q=1**. \n```{r}\n#| code-fold: true \n#| code-summary: 'ARIMA Model'\n#| warning: false\n\nset.seed(123)\n\nd=2\ni=1\ntemp= data.frame()\nls=matrix(rep(NA,6*25),nrow=25) # roughly nrow = 5x2 (see below)\n\n\nfor (p in 0:4)# p=0,1,2,3,4 : 5\n{\n  for(q in 0:4)# q=0,1,2,3,4 :5\n  {\n    model<- Arima(HYBE_ts,order=c(p,d,q),include.drift=TRUE) \n    ls[i,]= c(p,d,q,model$aic,model$bic,model$aicc)\n    i=i+1\n  }\n}\n\ntemp= as.data.frame(ls)\nnames(temp)= c(\"p\",\"d\",\"q\",\"AIC\",\"BIC\",\"AICc\")\n\n#temp\nknitr::kable(temp)\n```\n\n```{r}\n#| echo: false\nprint(\"AIC:\")\ntemp[which.min(temp$AIC),]\nprint(\"BIC:\")\ntemp[which.min(temp$BIC),]\nprint(\"AICc:\")\ntemp[which.min(temp$AICc),]\n```\n\n\n## Equation \n\nFrom the results of the `sarima()` function, we call say that the equation is as follows:\n\n\\begin{align}\n(1 - 0.9590\\beta - 0.4301\\beta^2)(1 - \\beta)(1 - \\beta)^2 (Y_t - \\mu) = (1 - 2.1072\\beta - 1.7438\\beta^2 + 0.6367\\beta^3) \\epsilon_t\n\\end{align}\n\n```{r}\n#| code-fold: true\nsarima(HYBE_ts, 2, 2, 3)\n```\n\n\n## auto.arima()\n\n`auto.arima()` concluded that ARIMA(4,1,2) is the best model. Comparing this to ARIMA(2,2,3), we can see that the AIC, BIC, and AICc values are much better. Additionally, the Ljung-Box statistic shows almost no autocorrelation within the model. \n\n```{r}\n#| code-fold: true\n#| warning: false\nauto.arima(HYBE_ts)\n\nsarima(HYBE_ts, 4, 1, 2)\n```\n\n## Forecasting\n```{r}\n#| code-fold: true \n#| code-summary: 'Forecasting'\n#| warning: false\nfit <- Arima(HYBE_ts, order=c(4, 1, 2))\nautoplot(forecast(fit, h = 365))\n```\n\n## Benchmark Comparison\n```{r}\n#| code-fold: true \n#| code-summary: 'Forecast comparison'\n#| warning: false\n\n\nautoplot(HYBE_ts) +\n  autolayer(meanf(HYBE_ts, h=365),\n            series=\"Mean\", PI=FALSE) +\n  autolayer(naive(HYBE_ts, h=365),\n            series=\"Naïve\", PI=FALSE) +\n  autolayer(snaive(HYBE_ts, h=365),\n            series=\"Seasonal naïve\", PI=FALSE) +\n  autolayer(forecast(fit, h=365),\n            series=\"Fit\", PI=FALSE) +\n  ggtitle(\"Forecasts for HYBE Stock Price\") +\n  xlab(\"Year\") + ylab(\"Price (USD)\") +\n  guides(colour=guide_legend(title=\"Forecast\"))\n```\n\n:::\n\nFrom the manual approach, we can also say that the ACF plot of residuals shows no significance, meaning the residuals are not correlated. Additionally, the p-values of the Ljung-Box statistic is on the lower side, however, we will continue and see whether auto.arima() creates a better model. Thus, after forecasting ARIMA(4,1,2), we can see that the forecast predicts a consistent stock price for the next year. Obviously, this doesn't seem feasible, as stock prices are constantly changing. However, what this does tell us is that there isn't an immediate positive trend in HYBE stock to say that the prediction would be upward. Therefore, we'll move forward and see how other KPOP labels and Western record labels may effect volitilaty and unpredictability of HYBE's future. \n\n--- \n\n# Popularity: KPOP\n\nIn order to get a better understanding of the popularity of KPOP as the years progress, we will create a ARMA model to forecast.\n\nFrom our [Exploratory Data Analysis](https://shriya-chinthak.georgetown.domains/DSAN_5600/eda.html), we noticed the following information: \n\n* Our original data, when plotted in an ACF and PACF plot, returned lags well within the significance bounds, meaning that the data was **stationary without differencing**. \n\n::: {.panel-tabset}\n\n## ACF & PACF \n```{r}\n#| code-fold: true\n\nkpop_data <- read.csv(\"cleaned_data/kpop_popularity.csv\")\nkpop_ts <- ts(kpop_data$popularity, frequency = 1)\n\nggAcf(kpop_ts)+ggtitle(\"ACF Plot for Popularity Score of KPOP Artists\")\nggPacf(kpop_ts)+ggtitle(\"PACF Plot for Popularity Score of KPOP Artists\")\n```\n\n## Manual ARMA\n```{r}\n#| code-fold: true\n#| warning: true\n\nset.seed(123)\n\nd=1\ni=1\ntemp= data.frame()\nls=matrix(rep(NA,6*25),nrow=25) # roughly nrow = 5x2 (see below)\n\n\nfor (p in 0:4)# p=0,1,2,3,4 : 5\n{\n  for(q in 0:4)# q=0,1,2,3,4 :5\n  {\n    model<- Arima(kpop_ts,order=c(p,d,q),include.drift=TRUE) \n    ls[i,]= c(p,d,q,model$aic,model$bic,model$aicc)\n    i=i+1\n  }\n}\n\ntemp= as.data.frame(ls)\nnames(temp)= c(\"p\",\"d\",\"q\",\"AIC\",\"BIC\",\"AICc\")\n\n#temp\nknitr::kable(temp)\n\n```\n\n```{r}\n#| echo: false\nprint(\"AIC:\")\ntemp[which.min(temp$AIC),]\nprint(\"BIC:\")\ntemp[which.min(temp$BIC),]\nprint(\"AICc:\")\ntemp[which.min(temp$AICc),]\n```\n\n\n## Equation\nThe resulting model is a constant function as a result of model selection. Unfortunelty, due to the lack of data points, we are unable to output the model diagnostics of the ARMA(0,0) model. Using the auto.arima() function, the equation for the model is written as follows. \n\n\\begin{align}\nx_{t} = w_{t} + 77.3352\n\\end{align}\n\n## auto.arima()\nThe auto.arima() function confirms our ACF and PACF plots with the model ARIMA(0,0,0)\n\n```{r}\n#| code-fold: true\nauto.arima(kpop_ts)\n```\n\n## Forecast\n\n```{r}\n#| code-fold: true\nfit <- Arima(kpop_ts, order=c(0, 0, 0))\nautoplot(forecast(fit))\n```\n\n## Benchmark Comparison\n\n```{r}\n#| code-fold: true\nautoplot(kpop_ts) +\n  autolayer(meanf(kpop_ts, h=11),\n            series=\"Mean\", PI=FALSE) +\n  autolayer(naive(kpop_ts, h=11),\n            series=\"Naïve\", PI=FALSE) +\n  autolayer(snaive(kpop_ts, h=11),\n            series=\"Seasonal naïve\", PI=FALSE) +\n  autolayer(forecast(fit, h=11),\n            series=\"Fit\", PI=FALSE) +\n  ggtitle(\"Forecasts for Yearly Average Popularity Score of KPOP Artists\") +\n  xlab(\"Year\") + ylab(\"Popularity Score\") +\n  guides(colour=guide_legend(title=\"Forecast\"))\n```\n\n:::\n\nSince we cannot see any siginificant lags in the ACF and PACF, we'll need to use a ARMA(0,0,0) model. However, running a manual and auto.arima() can help to decide the best approach. Through the manual approach, we found ARIMA(0,1,0) the best purely based on AIC and BIC. However, because this data cannot be differenced, ARIMA(0,0,0) is the best option, with auto.arima() solidfying this notion. As a result, the forecast is simply the mean value of the popularity, which is not a good indicator of the future forecast. The lack of data points unfortunelty prevented an in depth prediction, however, we can note that as as KPOP continues to be streamed, we will continue to see rising popularity. \n\n---\n\n# Popularity: Western\n\nIn order to get a better understanding of the popularity of Western artists as the years progress, we will create an ARMA model to forecast. As a reminder, due to the new Spotify API regulations, popularity scores are not public for all songs. Therefore, to use the metric we've extrapolated and averaged the scores. For more details, please [Data Visualizations](https://shriya-chinthak.georgetown.domains/DSAN_5600/data-visualization.html). \n\nFrom our [Exploratory Data Analysis](https://shriya-chinthak.georgetown.domains/DSAN_5600/eda.html), we noticed the following information: \n\n* Our original data, when plotted in an ACF and PACF plot, returned lags well within the significance bounds, meaning that the data was **stationary without differencing**. \n\n::: {.panel-tabset}\n\n## ACF & PACF\n\n```{r}\n#| code-fold: true\n\nwestern_data <- read.csv(\"cleaned_data/western_popularity.csv\")\nwestern_ts <- ts(western_data$popularity, frequency = 1)\n\nggAcf(western_ts)+ggtitle(\"ACF Plot for Popularity Score of Western Artists\")\nggPacf(western_ts)+ggtitle(\"PACF Plot for Popularity Score of Western Artists\")\n\n```\n\n## Manual ARIMA\n\n```{r}\n#| code-fold: true\n#| warning: true\n\nset.seed(123)\n\nd=1\ni=1\ntemp= data.frame()\nls=matrix(rep(NA,6*25),nrow=25) # roughly nrow = 5x2 (see below)\n\n\nfor (p in 0:4)# p=0,1,2,3,4 : 5\n{\n  for(q in 0:4)# q=0,1,2,3,4 :5\n  {\n    model<- Arima(western_ts,order=c(p,d,q),include.drift=TRUE) \n    ls[i,]= c(p,d,q,model$aic,model$bic,model$aicc)\n    i=i+1\n  }\n}\n\ntemp= as.data.frame(ls)\nnames(temp)= c(\"p\",\"d\",\"q\",\"AIC\",\"BIC\",\"AICc\")\n\n#temp\nknitr::kable(temp)\n\n```\n\n```{r}\n#| echo: false\nprint(\"AIC:\")\ntemp[which.min(temp$AIC),]\nprint(\"BIC:\")\ntemp[which.min(temp$BIC),]\nprint(\"AICc:\")\ntemp[which.min(temp$AICc),]\n```\n\n## Model Diagnotics\n\nThe manual approach suggested the model ARIMA(0,1,2) based on the lowest AIC and BIC values. After running the model diagnostics, we have the following. \n\n```{r}\n#| code-fold: true\nsarima(western_ts, 0, 1, 2)\n```\n\n## auto.arima()\nCross referencing with auto.arima() resulted in the model ARIMA(0,1,1). Through a model diagnostics analysis, we can see that while the AIC and BIC values are slightly higher, the Ljung-Box statistic p-values are much higher than the significance band, meaning that we fail to reject the null hypothesis and can say that the model is not autocorrelated. Therefore, we'll move forward with this model. \n\n\\begin{align}\n(1 - B)(Y_t - \\mu) = -0.7565 \\epsilon_t\n\\end{align}\n\n```{r}\n#| code-fold: true\nauto.arima(western_ts) #produced 0,1,1\nsarima(western_ts, 0, 1, 1)\n```\n\n## Forecast\n\n```{r}\n#| code-fold: true\nfit <- Arima(western_ts, order=c(0, 1, 1))\nautoplot(forecast(fit))\n```\n\n## Benchmark Comparison\n\n```{r}\n#| code-fold: true\n\n\nautoplot(western_ts) +\n  autolayer(meanf(western_ts, h=11),\n            series=\"Mean\", PI=FALSE) +\n  autolayer(naive(western_ts, h=11),\n            series=\"Naïve\", PI=FALSE) +\n  autolayer(snaive(western_ts, h=11),\n            series=\"Seasonal naïve\", PI=FALSE) +\n  autolayer(forecast(fit, h=11),\n            series=\"Fit\", PI=FALSE) +\n  ggtitle(\"Forecasts for Yearly Average Popularity Score of Western Artists\") +\n  xlab(\"Year\") + ylab(\"Popularity Score\") +\n  guides(colour=guide_legend(title=\"Forecast\"))\n```\n\n:::\n\nFor Western artists we saw that auto.arima() found a better model than our manual approach. The forecast shows a constant metric for the popularity score. Unfortunelty, this model, like the popularity score for KPOP, was not able to meet benchmark standards, simply due to the lack of data points. \n\nFor future analysis of popularity, we must investigate another outlet as opposed to the Spotify metric due to the new API regulations. A different metric with a string database would allow us to properly predict popularity based on genre and artist. However, what we can say is that popularity for both Western and KPOP artists fluctuate. To further estimate popularity of an artists, we must try to look at their musical characteristics and how this can predict popularity in time. \n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["styles.css"],"toc":true,"output-file":"arma.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.450","theme":"minty","title":"ARMA, ARIMA, and SARIMA Models"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}